{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>id_property</th>\n",
       "      <th>beds_basic</th>\n",
       "      <th>amount</th>\n",
       "      <th>area</th>\n",
       "      <th>floor</th>\n",
       "      <th>category</th>\n",
       "      <th>city</th>\n",
       "      <th>beds_additional</th>\n",
       "      <th>garden</th>\n",
       "      <th>...</th>\n",
       "      <th>hot_water_supply</th>\n",
       "      <th>no_smoking_rooms</th>\n",
       "      <th>in_mini_soccer</th>\n",
       "      <th>special_business</th>\n",
       "      <th>special_groups</th>\n",
       "      <th>unit_bedroom_mosquito_net</th>\n",
       "      <th>mosquito_net</th>\n",
       "      <th>property_internet_location</th>\n",
       "      <th>location_turistcomplex</th>\n",
       "      <th>in_food_local_speciality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24588</td>\n",
       "      <td>10043</td>\n",
       "      <td>4</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1.200568</td>\n",
       "      <td>1.821022</td>\n",
       "      <td>-0.159881</td>\n",
       "      <td>-0.448308</td>\n",
       "      <td>1.114105</td>\n",
       "      <td>1.223997</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.04695</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.121988</td>\n",
       "      <td>-0.054233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24589</td>\n",
       "      <td>10043</td>\n",
       "      <td>4</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1.200568</td>\n",
       "      <td>0.598643</td>\n",
       "      <td>-0.159881</td>\n",
       "      <td>-0.448308</td>\n",
       "      <td>1.114105</td>\n",
       "      <td>1.223997</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.04695</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.121988</td>\n",
       "      <td>-0.054233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24590</td>\n",
       "      <td>10043</td>\n",
       "      <td>4</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1.200568</td>\n",
       "      <td>-0.623736</td>\n",
       "      <td>-0.159881</td>\n",
       "      <td>-0.448308</td>\n",
       "      <td>-1.105967</td>\n",
       "      <td>1.223997</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.04695</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.121988</td>\n",
       "      <td>-0.054233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24593</td>\n",
       "      <td>10046</td>\n",
       "      <td>4</td>\n",
       "      <td>105.00</td>\n",
       "      <td>-0.150958</td>\n",
       "      <td>-0.623736</td>\n",
       "      <td>-0.159881</td>\n",
       "      <td>-0.448308</td>\n",
       "      <td>-1.105967</td>\n",
       "      <td>1.223997</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.04695</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.121988</td>\n",
       "      <td>-0.054233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24594</td>\n",
       "      <td>9098</td>\n",
       "      <td>4</td>\n",
       "      <td>120.00</td>\n",
       "      <td>0.194113</td>\n",
       "      <td>-0.623736</td>\n",
       "      <td>-0.159881</td>\n",
       "      <td>0.145470</td>\n",
       "      <td>0.004069</td>\n",
       "      <td>1.223997</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.04695</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.121988</td>\n",
       "      <td>-0.054233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1359</th>\n",
       "      <td>8166</td>\n",
       "      <td>3559</td>\n",
       "      <td>6</td>\n",
       "      <td>78.26</td>\n",
       "      <td>0.625451</td>\n",
       "      <td>-0.623736</td>\n",
       "      <td>-3.952536</td>\n",
       "      <td>-0.448308</td>\n",
       "      <td>1.114105</td>\n",
       "      <td>1.223997</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.04695</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.121988</td>\n",
       "      <td>-0.054233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1360</th>\n",
       "      <td>8175</td>\n",
       "      <td>3564</td>\n",
       "      <td>4</td>\n",
       "      <td>80.00</td>\n",
       "      <td>0.050333</td>\n",
       "      <td>1.821022</td>\n",
       "      <td>-2.056208</td>\n",
       "      <td>-0.448308</td>\n",
       "      <td>-1.105967</td>\n",
       "      <td>-0.816996</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.04695</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.121988</td>\n",
       "      <td>-0.054233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361</th>\n",
       "      <td>8176</td>\n",
       "      <td>3564</td>\n",
       "      <td>2</td>\n",
       "      <td>37.00</td>\n",
       "      <td>-1.042390</td>\n",
       "      <td>1.821022</td>\n",
       "      <td>-2.056208</td>\n",
       "      <td>-0.448308</td>\n",
       "      <td>-1.105967</td>\n",
       "      <td>-0.816996</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.04695</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.121988</td>\n",
       "      <td>-0.054233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1362</th>\n",
       "      <td>24567</td>\n",
       "      <td>10030</td>\n",
       "      <td>4</td>\n",
       "      <td>80.00</td>\n",
       "      <td>1.085545</td>\n",
       "      <td>0.598643</td>\n",
       "      <td>-0.159881</td>\n",
       "      <td>1.135099</td>\n",
       "      <td>1.114105</td>\n",
       "      <td>1.223997</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.04695</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.121988</td>\n",
       "      <td>-0.054233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1363</th>\n",
       "      <td>24575</td>\n",
       "      <td>10039</td>\n",
       "      <td>6</td>\n",
       "      <td>220.00</td>\n",
       "      <td>3.443527</td>\n",
       "      <td>-0.623736</td>\n",
       "      <td>1.736446</td>\n",
       "      <td>-0.151419</td>\n",
       "      <td>-1.105967</td>\n",
       "      <td>1.223997</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.04695</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.121988</td>\n",
       "      <td>-0.054233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1364 rows × 251 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  id_property  beds_basic  amount      area     floor  category  \\\n",
       "0     24588        10043           4  130.00  1.200568  1.821022 -0.159881   \n",
       "1     24589        10043           4  130.00  1.200568  0.598643 -0.159881   \n",
       "2     24590        10043           4  130.00  1.200568 -0.623736 -0.159881   \n",
       "3     24593        10046           4  105.00 -0.150958 -0.623736 -0.159881   \n",
       "4     24594         9098           4  120.00  0.194113 -0.623736 -0.159881   \n",
       "...     ...          ...         ...     ...       ...       ...       ...   \n",
       "1359   8166         3559           6   78.26  0.625451 -0.623736 -3.952536   \n",
       "1360   8175         3564           4   80.00  0.050333  1.821022 -2.056208   \n",
       "1361   8176         3564           2   37.00 -1.042390  1.821022 -2.056208   \n",
       "1362  24567        10030           4   80.00  1.085545  0.598643 -0.159881   \n",
       "1363  24575        10039           6  220.00  3.443527 -0.623736  1.736446   \n",
       "\n",
       "          city  beds_additional    garden  ...  hot_water_supply  \\\n",
       "0    -0.448308         1.114105  1.223997  ...          -0.03832   \n",
       "1    -0.448308         1.114105  1.223997  ...          -0.03832   \n",
       "2    -0.448308        -1.105967  1.223997  ...          -0.03832   \n",
       "3    -0.448308        -1.105967  1.223997  ...          -0.03832   \n",
       "4     0.145470         0.004069  1.223997  ...          -0.03832   \n",
       "...        ...              ...       ...  ...               ...   \n",
       "1359 -0.448308         1.114105  1.223997  ...          -0.03832   \n",
       "1360 -0.448308        -1.105967 -0.816996  ...          -0.03832   \n",
       "1361 -0.448308        -1.105967 -0.816996  ...          -0.03832   \n",
       "1362  1.135099         1.114105  1.223997  ...          -0.03832   \n",
       "1363 -0.151419        -1.105967  1.223997  ...          -0.03832   \n",
       "\n",
       "      no_smoking_rooms  in_mini_soccer  special_business  special_groups  \\\n",
       "0            -0.054233       -0.027086          -0.03832       -0.027086   \n",
       "1            -0.054233       -0.027086          -0.03832       -0.027086   \n",
       "2            -0.054233       -0.027086          -0.03832       -0.027086   \n",
       "3            -0.054233       -0.027086          -0.03832       -0.027086   \n",
       "4            -0.054233       -0.027086          -0.03832       -0.027086   \n",
       "...                ...             ...               ...             ...   \n",
       "1359         -0.054233       -0.027086          -0.03832       -0.027086   \n",
       "1360         -0.054233       -0.027086          -0.03832       -0.027086   \n",
       "1361         -0.054233       -0.027086          -0.03832       -0.027086   \n",
       "1362         -0.054233       -0.027086          -0.03832       -0.027086   \n",
       "1363         -0.054233       -0.027086          -0.03832       -0.027086   \n",
       "\n",
       "      unit_bedroom_mosquito_net  mosquito_net  property_internet_location  \\\n",
       "0                     -0.054233      -0.04695                   -0.027086   \n",
       "1                     -0.054233      -0.04695                   -0.027086   \n",
       "2                     -0.054233      -0.04695                   -0.027086   \n",
       "3                     -0.054233      -0.04695                   -0.027086   \n",
       "4                     -0.054233      -0.04695                   -0.027086   \n",
       "...                         ...           ...                         ...   \n",
       "1359                  -0.054233      -0.04695                   -0.027086   \n",
       "1360                  -0.054233      -0.04695                   -0.027086   \n",
       "1361                  -0.054233      -0.04695                   -0.027086   \n",
       "1362                  -0.054233      -0.04695                   -0.027086   \n",
       "1363                  -0.054233      -0.04695                   -0.027086   \n",
       "\n",
       "      location_turistcomplex  in_food_local_speciality  \n",
       "0                  -0.121988                 -0.054233  \n",
       "1                  -0.121988                 -0.054233  \n",
       "2                  -0.121988                 -0.054233  \n",
       "3                  -0.121988                 -0.054233  \n",
       "4                  -0.121988                 -0.054233  \n",
       "...                      ...                       ...  \n",
       "1359               -0.121988                 -0.054233  \n",
       "1360               -0.121988                 -0.054233  \n",
       "1361               -0.121988                 -0.054233  \n",
       "1362               -0.121988                 -0.054233  \n",
       "1363               -0.121988                 -0.054233  \n",
       "\n",
       "[1364 rows x 251 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"gen_data/gen2/nopca_standard.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>id_property</th>\n",
       "      <th>beds_basic</th>\n",
       "      <th>amount</th>\n",
       "      <th>area</th>\n",
       "      <th>floor</th>\n",
       "      <th>category</th>\n",
       "      <th>city</th>\n",
       "      <th>beds_additional</th>\n",
       "      <th>garden</th>\n",
       "      <th>...</th>\n",
       "      <th>hot_water_supply</th>\n",
       "      <th>no_smoking_rooms</th>\n",
       "      <th>in_mini_soccer</th>\n",
       "      <th>special_business</th>\n",
       "      <th>special_groups</th>\n",
       "      <th>unit_bedroom_mosquito_net</th>\n",
       "      <th>mosquito_net</th>\n",
       "      <th>property_internet_location</th>\n",
       "      <th>location_turistcomplex</th>\n",
       "      <th>in_food_local_speciality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24588</td>\n",
       "      <td>10043</td>\n",
       "      <td>4</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1.200568</td>\n",
       "      <td>1.821022</td>\n",
       "      <td>-0.159881</td>\n",
       "      <td>-0.448308</td>\n",
       "      <td>1.114105</td>\n",
       "      <td>1.223997</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.04695</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.121988</td>\n",
       "      <td>-0.054233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24589</td>\n",
       "      <td>10043</td>\n",
       "      <td>4</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1.200568</td>\n",
       "      <td>0.598643</td>\n",
       "      <td>-0.159881</td>\n",
       "      <td>-0.448308</td>\n",
       "      <td>1.114105</td>\n",
       "      <td>1.223997</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.04695</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.121988</td>\n",
       "      <td>-0.054233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24590</td>\n",
       "      <td>10043</td>\n",
       "      <td>4</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1.200568</td>\n",
       "      <td>-0.623736</td>\n",
       "      <td>-0.159881</td>\n",
       "      <td>-0.448308</td>\n",
       "      <td>-1.105967</td>\n",
       "      <td>1.223997</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.04695</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.121988</td>\n",
       "      <td>-0.054233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24593</td>\n",
       "      <td>10046</td>\n",
       "      <td>4</td>\n",
       "      <td>105.0</td>\n",
       "      <td>-0.150958</td>\n",
       "      <td>-0.623736</td>\n",
       "      <td>-0.159881</td>\n",
       "      <td>-0.448308</td>\n",
       "      <td>-1.105967</td>\n",
       "      <td>1.223997</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.04695</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.121988</td>\n",
       "      <td>-0.054233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24594</td>\n",
       "      <td>9098</td>\n",
       "      <td>4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.194113</td>\n",
       "      <td>-0.623736</td>\n",
       "      <td>-0.159881</td>\n",
       "      <td>0.145470</td>\n",
       "      <td>0.004069</td>\n",
       "      <td>1.223997</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.04695</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.121988</td>\n",
       "      <td>-0.054233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>24512</td>\n",
       "      <td>8028</td>\n",
       "      <td>4</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1.488127</td>\n",
       "      <td>1.821022</td>\n",
       "      <td>-0.159881</td>\n",
       "      <td>-0.448308</td>\n",
       "      <td>-1.105967</td>\n",
       "      <td>1.223997</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.04695</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.121988</td>\n",
       "      <td>-0.054233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>24513</td>\n",
       "      <td>10013</td>\n",
       "      <td>4</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.194113</td>\n",
       "      <td>0.598643</td>\n",
       "      <td>-0.159881</td>\n",
       "      <td>-0.448308</td>\n",
       "      <td>0.004069</td>\n",
       "      <td>-0.816996</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.04695</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.121988</td>\n",
       "      <td>-0.054233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>24516</td>\n",
       "      <td>10014</td>\n",
       "      <td>4</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-0.237225</td>\n",
       "      <td>-0.623736</td>\n",
       "      <td>-0.159881</td>\n",
       "      <td>1.431988</td>\n",
       "      <td>-1.105967</td>\n",
       "      <td>-0.816996</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.04695</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.121988</td>\n",
       "      <td>-0.054233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>8175</td>\n",
       "      <td>3564</td>\n",
       "      <td>4</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.050333</td>\n",
       "      <td>1.821022</td>\n",
       "      <td>-2.056208</td>\n",
       "      <td>-0.448308</td>\n",
       "      <td>-1.105967</td>\n",
       "      <td>-0.816996</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.04695</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.121988</td>\n",
       "      <td>-0.054233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>24567</td>\n",
       "      <td>10030</td>\n",
       "      <td>4</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.085545</td>\n",
       "      <td>0.598643</td>\n",
       "      <td>-0.159881</td>\n",
       "      <td>1.135099</td>\n",
       "      <td>1.114105</td>\n",
       "      <td>1.223997</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.04695</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.121988</td>\n",
       "      <td>-0.054233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>508 rows × 251 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  id_property  beds_basic  amount      area     floor  category  \\\n",
       "0    24588        10043           4   130.0  1.200568  1.821022 -0.159881   \n",
       "1    24589        10043           4   130.0  1.200568  0.598643 -0.159881   \n",
       "2    24590        10043           4   130.0  1.200568 -0.623736 -0.159881   \n",
       "3    24593        10046           4   105.0 -0.150958 -0.623736 -0.159881   \n",
       "4    24594         9098           4   120.0  0.194113 -0.623736 -0.159881   \n",
       "..     ...          ...         ...     ...       ...       ...       ...   \n",
       "503  24512         8028           4   160.0  1.488127  1.821022 -0.159881   \n",
       "504  24513        10013           4    85.0  0.194113  0.598643 -0.159881   \n",
       "505  24516        10014           4    95.0 -0.237225 -0.623736 -0.159881   \n",
       "506   8175         3564           4    80.0  0.050333  1.821022 -2.056208   \n",
       "507  24567        10030           4    80.0  1.085545  0.598643 -0.159881   \n",
       "\n",
       "         city  beds_additional    garden  ...  hot_water_supply  \\\n",
       "0   -0.448308         1.114105  1.223997  ...          -0.03832   \n",
       "1   -0.448308         1.114105  1.223997  ...          -0.03832   \n",
       "2   -0.448308        -1.105967  1.223997  ...          -0.03832   \n",
       "3   -0.448308        -1.105967  1.223997  ...          -0.03832   \n",
       "4    0.145470         0.004069  1.223997  ...          -0.03832   \n",
       "..        ...              ...       ...  ...               ...   \n",
       "503 -0.448308        -1.105967  1.223997  ...          -0.03832   \n",
       "504 -0.448308         0.004069 -0.816996  ...          -0.03832   \n",
       "505  1.431988        -1.105967 -0.816996  ...          -0.03832   \n",
       "506 -0.448308        -1.105967 -0.816996  ...          -0.03832   \n",
       "507  1.135099         1.114105  1.223997  ...          -0.03832   \n",
       "\n",
       "     no_smoking_rooms  in_mini_soccer  special_business  special_groups  \\\n",
       "0           -0.054233       -0.027086          -0.03832       -0.027086   \n",
       "1           -0.054233       -0.027086          -0.03832       -0.027086   \n",
       "2           -0.054233       -0.027086          -0.03832       -0.027086   \n",
       "3           -0.054233       -0.027086          -0.03832       -0.027086   \n",
       "4           -0.054233       -0.027086          -0.03832       -0.027086   \n",
       "..                ...             ...               ...             ...   \n",
       "503         -0.054233       -0.027086          -0.03832       -0.027086   \n",
       "504         -0.054233       -0.027086          -0.03832       -0.027086   \n",
       "505         -0.054233       -0.027086          -0.03832       -0.027086   \n",
       "506         -0.054233       -0.027086          -0.03832       -0.027086   \n",
       "507         -0.054233       -0.027086          -0.03832       -0.027086   \n",
       "\n",
       "     unit_bedroom_mosquito_net  mosquito_net  property_internet_location  \\\n",
       "0                    -0.054233      -0.04695                   -0.027086   \n",
       "1                    -0.054233      -0.04695                   -0.027086   \n",
       "2                    -0.054233      -0.04695                   -0.027086   \n",
       "3                    -0.054233      -0.04695                   -0.027086   \n",
       "4                    -0.054233      -0.04695                   -0.027086   \n",
       "..                         ...           ...                         ...   \n",
       "503                  -0.054233      -0.04695                   -0.027086   \n",
       "504                  -0.054233      -0.04695                   -0.027086   \n",
       "505                  -0.054233      -0.04695                   -0.027086   \n",
       "506                  -0.054233      -0.04695                   -0.027086   \n",
       "507                  -0.054233      -0.04695                   -0.027086   \n",
       "\n",
       "     location_turistcomplex  in_food_local_speciality  \n",
       "0                 -0.121988                 -0.054233  \n",
       "1                 -0.121988                 -0.054233  \n",
       "2                 -0.121988                 -0.054233  \n",
       "3                 -0.121988                 -0.054233  \n",
       "4                 -0.121988                 -0.054233  \n",
       "..                      ...                       ...  \n",
       "503               -0.121988                 -0.054233  \n",
       "504               -0.121988                 -0.054233  \n",
       "505               -0.121988                 -0.054233  \n",
       "506               -0.121988                 -0.054233  \n",
       "507               -0.121988                 -0.054233  \n",
       "\n",
       "[508 rows x 251 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4=df[df[\"beds_basic\"]==4]\n",
    "df4.reset_index(inplace=True,drop=True)\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df4.iloc[:,4:]\n",
    "Y=df4.loc[:,\"amount\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(508, 247)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(381, 247)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121.15246719160106, 116.90314960629922)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.mean(), y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([317.,  54.,   2.,   1.,   0.,   0.,   2.,   0.,   4.,   1.]),\n",
       " array([ 52. , 136.8, 221.6, 306.4, 391.2, 476. , 560.8, 645.6, 730.4,\n",
       "        815.2, 900. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#import keras\n",
    "\n",
    "model_1 = tf.keras.models.Sequential()\n",
    "model_1.add(tf.keras.Input(shape=(247,)))\n",
    "#model_1.add(tf.keras.layers.Dense(247, activation=\"relu\"))\n",
    "model_1.add(tf.keras.layers.Dense(128, activation=\"relu\"))\n",
    "#model_1.add(tf.keras.layers.Dense(64, activation=\"relu\"))\n",
    "#model_1.add(tf.keras.layers.Dropout(0.05))\n",
    "model_1.add(tf.keras.layers.Dense(1))\n",
    "model_1.compile(loss=\"mse\", optimizer=tf.keras.optimizers.Adam(learning_rate=0.003), metrics=[\"mse\"])\n",
    "#model_1.compile(loss=config_1.loss_function, optimizer=tf.keras.optimizers.Adam(config_1.learning_rate), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "24/24 [==============================] - 1s 10ms/step - loss: 22091.1445 - mse: 22091.1445 - val_loss: 20175.0391 - val_mse: 20175.0391\n",
      "Epoch 2/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 18198.2852 - mse: 18198.2852 - val_loss: 16047.2920 - val_mse: 16047.2920\n",
      "Epoch 3/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 12813.5762 - mse: 12813.5762 - val_loss: 11732.4941 - val_mse: 11732.4941\n",
      "Epoch 4/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 8712.5010 - mse: 8712.5010 - val_loss: 9617.2578 - val_mse: 9617.2578\n",
      "Epoch 5/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6995.9985 - mse: 6995.9985 - val_loss: 9395.7812 - val_mse: 9395.7812\n",
      "Epoch 6/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 6513.1641 - mse: 6513.1641 - val_loss: 9314.1885 - val_mse: 9314.1885\n",
      "Epoch 7/300\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 6109.1904 - mse: 6109.1904 - val_loss: 9294.8682 - val_mse: 9294.8682\n",
      "Epoch 8/300\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 5811.6792 - mse: 5811.6792 - val_loss: 9301.5195 - val_mse: 9301.5195\n",
      "Epoch 9/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5486.1694 - mse: 5486.1694 - val_loss: 9179.5762 - val_mse: 9179.5762\n",
      "Epoch 10/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5410.0454 - mse: 5410.0454 - val_loss: 9198.5986 - val_mse: 9198.5986\n",
      "Epoch 11/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 5093.4565 - mse: 5093.4565 - val_loss: 9044.9844 - val_mse: 9044.9844\n",
      "Epoch 12/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4765.4248 - mse: 4765.4248 - val_loss: 9008.3740 - val_mse: 9008.3740\n",
      "Epoch 13/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4509.5288 - mse: 4509.5288 - val_loss: 8956.7139 - val_mse: 8956.7139\n",
      "Epoch 14/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4278.6865 - mse: 4278.6865 - val_loss: 8863.4785 - val_mse: 8863.4785\n",
      "Epoch 15/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4026.1868 - mse: 4026.1868 - val_loss: 8805.7910 - val_mse: 8805.7910\n",
      "Epoch 16/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3831.9426 - mse: 3831.9426 - val_loss: 8682.2363 - val_mse: 8682.2363\n",
      "Epoch 17/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3571.4583 - mse: 3571.4583 - val_loss: 8647.4258 - val_mse: 8647.4258\n",
      "Epoch 18/300\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3368.2441 - mse: 3368.2441 - val_loss: 8459.4248 - val_mse: 8459.4248\n",
      "Epoch 19/300\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3171.4800 - mse: 3171.4800 - val_loss: 8471.9307 - val_mse: 8471.9307\n",
      "Epoch 20/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2963.2310 - mse: 2963.2310 - val_loss: 8257.1943 - val_mse: 8257.1943\n",
      "Epoch 21/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2781.5879 - mse: 2781.5879 - val_loss: 8286.9658 - val_mse: 8286.9658\n",
      "Epoch 22/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2548.3997 - mse: 2548.3997 - val_loss: 8060.5195 - val_mse: 8060.5195\n",
      "Epoch 23/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2436.8855 - mse: 2436.8855 - val_loss: 7990.2231 - val_mse: 7990.2231\n",
      "Epoch 24/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2197.2617 - mse: 2197.2617 - val_loss: 7921.3838 - val_mse: 7921.3838\n",
      "Epoch 25/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2070.2964 - mse: 2070.2964 - val_loss: 7855.2798 - val_mse: 7855.2798\n",
      "Epoch 26/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1901.4989 - mse: 1901.4989 - val_loss: 7677.3032 - val_mse: 7677.3032\n",
      "Epoch 27/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1779.3939 - mse: 1779.3939 - val_loss: 7554.1978 - val_mse: 7554.1978\n",
      "Epoch 28/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1675.3116 - mse: 1675.3116 - val_loss: 7686.7495 - val_mse: 7686.7495\n",
      "Epoch 29/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1485.0128 - mse: 1485.0128 - val_loss: 7449.6045 - val_mse: 7449.6045\n",
      "Epoch 30/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1394.4246 - mse: 1394.4246 - val_loss: 7315.0195 - val_mse: 7315.0195\n",
      "Epoch 31/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1271.3492 - mse: 1271.3492 - val_loss: 7430.4546 - val_mse: 7430.4546\n",
      "Epoch 32/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 1186.2997 - mse: 1186.2997 - val_loss: 7319.0156 - val_mse: 7319.0156\n",
      "Epoch 33/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1071.5781 - mse: 1071.5781 - val_loss: 7243.2695 - val_mse: 7243.2695\n",
      "Epoch 34/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 997.2393 - mse: 997.2393 - val_loss: 7223.9316 - val_mse: 7223.9316\n",
      "Epoch 35/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 945.3748 - mse: 945.3748 - val_loss: 7209.3296 - val_mse: 7209.3296\n",
      "Epoch 36/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 899.0055 - mse: 899.0055 - val_loss: 7019.4058 - val_mse: 7019.4058\n",
      "Epoch 37/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 813.4319 - mse: 813.4319 - val_loss: 7014.6689 - val_mse: 7014.6689\n",
      "Epoch 38/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 733.2668 - mse: 733.2668 - val_loss: 7000.6602 - val_mse: 7000.6602\n",
      "Epoch 39/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 662.3727 - mse: 662.3727 - val_loss: 6925.5200 - val_mse: 6925.5200\n",
      "Epoch 40/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 614.1580 - mse: 614.1580 - val_loss: 6957.5947 - val_mse: 6957.5947\n",
      "Epoch 41/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 606.5003 - mse: 606.5003 - val_loss: 6737.0635 - val_mse: 6737.0635\n",
      "Epoch 42/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 558.2963 - mse: 558.2963 - val_loss: 6726.1670 - val_mse: 6726.1670\n",
      "Epoch 43/300\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 552.3964 - mse: 552.3964 - val_loss: 6753.8008 - val_mse: 6753.8008\n",
      "Epoch 44/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 478.6008 - mse: 478.6008 - val_loss: 6634.9736 - val_mse: 6634.9736\n",
      "Epoch 45/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 437.9630 - mse: 437.9630 - val_loss: 6619.5005 - val_mse: 6619.5005\n",
      "Epoch 46/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 413.8683 - mse: 413.8683 - val_loss: 6705.3003 - val_mse: 6705.3003\n",
      "Epoch 47/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 401.1777 - mse: 401.1777 - val_loss: 6499.0991 - val_mse: 6499.0991\n",
      "Epoch 48/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 385.2603 - mse: 385.2603 - val_loss: 6518.1602 - val_mse: 6518.1602\n",
      "Epoch 49/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 327.0088 - mse: 327.0088 - val_loss: 6486.3687 - val_mse: 6486.3687\n",
      "Epoch 50/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 318.3789 - mse: 318.3789 - val_loss: 6435.1953 - val_mse: 6435.1953\n",
      "Epoch 51/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 324.3496 - mse: 324.3496 - val_loss: 6508.3867 - val_mse: 6508.3867\n",
      "Epoch 52/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 307.2336 - mse: 307.2336 - val_loss: 6428.1313 - val_mse: 6428.1313\n",
      "Epoch 53/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 253.2730 - mse: 253.2730 - val_loss: 6342.6123 - val_mse: 6342.6123\n",
      "Epoch 54/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 237.6329 - mse: 237.6329 - val_loss: 6307.2744 - val_mse: 6307.2744\n",
      "Epoch 55/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 224.2392 - mse: 224.2392 - val_loss: 6295.8291 - val_mse: 6295.8291\n",
      "Epoch 56/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 205.0646 - mse: 205.0646 - val_loss: 6258.0913 - val_mse: 6258.0913\n",
      "Epoch 57/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 187.6281 - mse: 187.6281 - val_loss: 6229.1348 - val_mse: 6229.1348\n",
      "Epoch 58/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 185.4065 - mse: 185.4065 - val_loss: 6235.1235 - val_mse: 6235.1235\n",
      "Epoch 59/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 182.0308 - mse: 182.0308 - val_loss: 6167.4351 - val_mse: 6167.4351\n",
      "Epoch 60/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 167.7158 - mse: 167.7158 - val_loss: 6168.8853 - val_mse: 6168.8853\n",
      "Epoch 61/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 161.9656 - mse: 161.9656 - val_loss: 6097.4463 - val_mse: 6097.4463\n",
      "Epoch 62/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 152.3340 - mse: 152.3340 - val_loss: 6128.1279 - val_mse: 6128.1279\n",
      "Epoch 63/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 133.6914 - mse: 133.6914 - val_loss: 6065.0391 - val_mse: 6065.0391\n",
      "Epoch 64/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 133.2782 - mse: 133.2782 - val_loss: 6027.3228 - val_mse: 6027.3228\n",
      "Epoch 65/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 122.7635 - mse: 122.7635 - val_loss: 6102.2148 - val_mse: 6102.2148\n",
      "Epoch 66/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 114.6786 - mse: 114.6786 - val_loss: 5995.6675 - val_mse: 5995.6675\n",
      "Epoch 67/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 109.0671 - mse: 109.0671 - val_loss: 5987.4370 - val_mse: 5987.4370\n",
      "Epoch 68/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 111.4010 - mse: 111.4010 - val_loss: 5979.5586 - val_mse: 5979.5586\n",
      "Epoch 69/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 96.2766 - mse: 96.2766 - val_loss: 5972.0977 - val_mse: 5972.0981\n",
      "Epoch 70/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 88.1190 - mse: 88.1190 - val_loss: 5943.6333 - val_mse: 5943.6338\n",
      "Epoch 71/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 84.9717 - mse: 84.9717 - val_loss: 5955.9775 - val_mse: 5955.9775\n",
      "Epoch 72/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 93.0845 - mse: 93.0845 - val_loss: 5922.3228 - val_mse: 5922.3228\n",
      "Epoch 73/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 101.2562 - mse: 101.2562 - val_loss: 5963.0029 - val_mse: 5963.0029\n",
      "Epoch 74/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 93.1250 - mse: 93.1250 - val_loss: 5945.8486 - val_mse: 5945.8486\n",
      "Epoch 75/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 95.2930 - mse: 95.2930 - val_loss: 5901.1196 - val_mse: 5901.1196\n",
      "Epoch 76/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 87.6908 - mse: 87.6908 - val_loss: 6043.3296 - val_mse: 6043.3296\n",
      "Epoch 77/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 114.5448 - mse: 114.5448 - val_loss: 5911.8286 - val_mse: 5911.8286\n",
      "Epoch 78/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 108.8579 - mse: 108.8579 - val_loss: 5943.9424 - val_mse: 5943.9424\n",
      "Epoch 79/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 83.8968 - mse: 83.8968 - val_loss: 5881.3286 - val_mse: 5881.3286\n",
      "Epoch 80/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 72.2574 - mse: 72.2574 - val_loss: 5885.5811 - val_mse: 5885.5811\n",
      "Epoch 81/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 70.8720 - mse: 70.8720 - val_loss: 5874.1758 - val_mse: 5874.1758\n",
      "Epoch 82/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 73.1507 - mse: 73.1507 - val_loss: 5916.7236 - val_mse: 5916.7236\n",
      "Epoch 83/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 95.9574 - mse: 95.9574 - val_loss: 5929.6406 - val_mse: 5929.6406\n",
      "Epoch 84/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 83.5792 - mse: 83.5792 - val_loss: 5918.5371 - val_mse: 5918.5371\n",
      "Epoch 85/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 85.5043 - mse: 85.5043 - val_loss: 5830.2690 - val_mse: 5830.2690\n",
      "Epoch 86/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 73.8054 - mse: 73.8054 - val_loss: 5832.4863 - val_mse: 5832.4863\n",
      "Epoch 87/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 77.0982 - mse: 77.0982 - val_loss: 5842.7065 - val_mse: 5842.7065\n",
      "Epoch 88/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 79.9706 - mse: 79.9706 - val_loss: 5853.1724 - val_mse: 5853.1724\n",
      "Epoch 89/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 71.0713 - mse: 71.0713 - val_loss: 5859.4971 - val_mse: 5859.4971\n",
      "Epoch 90/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 59.7843 - mse: 59.7843 - val_loss: 5839.6553 - val_mse: 5839.6553\n",
      "Epoch 91/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 54.2495 - mse: 54.2495 - val_loss: 5848.4023 - val_mse: 5848.4023\n",
      "Epoch 92/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 54.7378 - mse: 54.7378 - val_loss: 5835.6919 - val_mse: 5835.6919\n",
      "Epoch 93/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 72.8904 - mse: 72.8904 - val_loss: 5887.3765 - val_mse: 5887.3765\n",
      "Epoch 94/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 77.5654 - mse: 77.5654 - val_loss: 5849.2051 - val_mse: 5849.2051\n",
      "Epoch 95/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 65.3015 - mse: 65.3015 - val_loss: 5888.4868 - val_mse: 5888.4868\n",
      "Epoch 96/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 54.7443 - mse: 54.7443 - val_loss: 5821.0688 - val_mse: 5821.0684\n",
      "Epoch 97/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 48.5876 - mse: 48.5876 - val_loss: 5796.7896 - val_mse: 5796.7896\n",
      "Epoch 98/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 56.1604 - mse: 56.1604 - val_loss: 5919.1655 - val_mse: 5919.1655\n",
      "Epoch 99/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 77.1617 - mse: 77.1617 - val_loss: 5841.5049 - val_mse: 5841.5049\n",
      "Epoch 100/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 44.2895 - mse: 44.2895 - val_loss: 5845.6333 - val_mse: 5845.6333\n",
      "Epoch 101/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 40.8489 - mse: 40.8489 - val_loss: 5814.9653 - val_mse: 5814.9653\n",
      "Epoch 102/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 37.2738 - mse: 37.2738 - val_loss: 5822.1782 - val_mse: 5822.1782\n",
      "Epoch 103/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 35.3788 - mse: 35.3788 - val_loss: 5797.0742 - val_mse: 5797.0742\n",
      "Epoch 104/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 35.1877 - mse: 35.1877 - val_loss: 5856.9331 - val_mse: 5856.9331\n",
      "Epoch 105/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 33.2697 - mse: 33.2697 - val_loss: 5823.0825 - val_mse: 5823.0825\n",
      "Epoch 106/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 33.4071 - mse: 33.4071 - val_loss: 5808.5942 - val_mse: 5808.5942\n",
      "Epoch 107/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 31.4706 - mse: 31.4706 - val_loss: 5810.7549 - val_mse: 5810.7549\n",
      "Epoch 108/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 34.8027 - mse: 34.8027 - val_loss: 5833.9097 - val_mse: 5833.9097\n",
      "Epoch 109/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 42.0612 - mse: 42.0612 - val_loss: 5783.4819 - val_mse: 5783.4819\n",
      "Epoch 110/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 42.0623 - mse: 42.0623 - val_loss: 5752.6865 - val_mse: 5752.6865\n",
      "Epoch 111/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 37.2698 - mse: 37.2698 - val_loss: 5813.9697 - val_mse: 5813.9697\n",
      "Epoch 112/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 39.0935 - mse: 39.0935 - val_loss: 5791.6763 - val_mse: 5791.6763\n",
      "Epoch 113/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 44.1548 - mse: 44.1548 - val_loss: 5867.9814 - val_mse: 5867.9814\n",
      "Epoch 114/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 58.3766 - mse: 58.3766 - val_loss: 5774.9756 - val_mse: 5774.9756\n",
      "Epoch 115/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 44.3191 - mse: 44.3191 - val_loss: 5847.4604 - val_mse: 5847.4604\n",
      "Epoch 116/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 43.1724 - mse: 43.1724 - val_loss: 5825.7490 - val_mse: 5825.7490\n",
      "Epoch 117/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 41.0206 - mse: 41.0206 - val_loss: 5854.5684 - val_mse: 5854.5684\n",
      "Epoch 118/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 56.4556 - mse: 56.4556 - val_loss: 5729.9673 - val_mse: 5729.9673\n",
      "Epoch 119/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 67.3914 - mse: 67.3914 - val_loss: 5759.8530 - val_mse: 5759.8530\n",
      "Epoch 120/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 72.0944 - mse: 72.0944 - val_loss: 5814.6860 - val_mse: 5814.6860\n",
      "Epoch 121/300\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 58.9002 - mse: 58.9002 - val_loss: 5835.8970 - val_mse: 5835.8970\n",
      "Epoch 122/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 63.5956 - mse: 63.5956 - val_loss: 5771.3530 - val_mse: 5771.3530\n",
      "Epoch 123/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 66.9009 - mse: 66.9009 - val_loss: 5766.0991 - val_mse: 5766.0991\n",
      "Epoch 124/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 68.9080 - mse: 68.9080 - val_loss: 5801.6133 - val_mse: 5801.6133\n",
      "Epoch 125/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 70.7973 - mse: 70.7973 - val_loss: 5747.3315 - val_mse: 5747.3315\n",
      "Epoch 126/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 69.1746 - mse: 69.1746 - val_loss: 5789.7705 - val_mse: 5789.7705\n",
      "Epoch 127/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 56.8979 - mse: 56.8979 - val_loss: 5821.6660 - val_mse: 5821.6660\n",
      "Epoch 128/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 65.7543 - mse: 65.7543 - val_loss: 5728.0586 - val_mse: 5728.0586\n",
      "Epoch 129/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 57.1577 - mse: 57.1577 - val_loss: 5736.3008 - val_mse: 5736.3008\n",
      "Epoch 130/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 71.4245 - mse: 71.4245 - val_loss: 5806.6338 - val_mse: 5806.6338\n",
      "Epoch 131/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 58.1381 - mse: 58.1381 - val_loss: 5797.8799 - val_mse: 5797.8799\n",
      "Epoch 132/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 50.4859 - mse: 50.4859 - val_loss: 5760.4214 - val_mse: 5760.4214\n",
      "Epoch 133/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 40.2203 - mse: 40.2203 - val_loss: 5783.8130 - val_mse: 5783.8130\n",
      "Epoch 134/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 54.4268 - mse: 54.4268 - val_loss: 5764.2446 - val_mse: 5764.2446\n",
      "Epoch 135/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 46.7976 - mse: 46.7976 - val_loss: 5867.5063 - val_mse: 5867.5063\n",
      "Epoch 136/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 52.8368 - mse: 52.8368 - val_loss: 5710.7427 - val_mse: 5710.7427\n",
      "Epoch 137/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 62.8947 - mse: 62.8947 - val_loss: 5882.7500 - val_mse: 5882.7500\n",
      "Epoch 138/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 43.3858 - mse: 43.3858 - val_loss: 5727.1812 - val_mse: 5727.1812\n",
      "Epoch 139/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 36.8478 - mse: 36.8478 - val_loss: 5804.7578 - val_mse: 5804.7578\n",
      "Epoch 140/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 52.8142 - mse: 52.8142 - val_loss: 5724.9922 - val_mse: 5724.9922\n",
      "Epoch 141/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 81.0089 - mse: 81.0089 - val_loss: 5750.2754 - val_mse: 5750.2754\n",
      "Epoch 142/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 49.6207 - mse: 49.6207 - val_loss: 5754.6030 - val_mse: 5754.6030\n",
      "Epoch 143/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 40.2045 - mse: 40.2045 - val_loss: 5811.9116 - val_mse: 5811.9116\n",
      "Epoch 144/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 34.9963 - mse: 34.9963 - val_loss: 5757.4868 - val_mse: 5757.4868\n",
      "Epoch 145/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 30.9111 - mse: 30.9111 - val_loss: 5844.7720 - val_mse: 5844.7720\n",
      "Epoch 146/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 29.0720 - mse: 29.0720 - val_loss: 5748.9116 - val_mse: 5748.9116\n",
      "Epoch 147/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 23.9443 - mse: 23.9443 - val_loss: 5772.4512 - val_mse: 5772.4512\n",
      "Epoch 148/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 24.6122 - mse: 24.6122 - val_loss: 5826.6807 - val_mse: 5826.6807\n",
      "Epoch 149/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 21.7387 - mse: 21.7387 - val_loss: 5749.6606 - val_mse: 5749.6606\n",
      "Epoch 150/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 18.1909 - mse: 18.1909 - val_loss: 5734.5508 - val_mse: 5734.5508\n",
      "Epoch 151/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 16.4712 - mse: 16.4712 - val_loss: 5749.1294 - val_mse: 5749.1294\n",
      "Epoch 152/300\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 14.7742 - mse: 14.7742 - val_loss: 5786.5718 - val_mse: 5786.5718\n",
      "Epoch 153/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.9140 - mse: 12.9140 - val_loss: 5778.5669 - val_mse: 5778.5669\n",
      "Epoch 154/300\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 14.3587 - mse: 14.3587 - val_loss: 5814.3232 - val_mse: 5814.3232\n",
      "Epoch 155/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 15.3491 - mse: 15.3491 - val_loss: 5785.3516 - val_mse: 5785.3516\n",
      "Epoch 156/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 14.5208 - mse: 14.5208 - val_loss: 5804.6646 - val_mse: 5804.6646\n",
      "Epoch 157/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 13.4716 - mse: 13.4716 - val_loss: 5763.0356 - val_mse: 5763.0356\n",
      "Epoch 158/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 14.1195 - mse: 14.1195 - val_loss: 5765.7700 - val_mse: 5765.7700\n",
      "Epoch 159/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 17.6179 - mse: 17.6179 - val_loss: 5757.0483 - val_mse: 5757.0483\n",
      "Epoch 160/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 20.4877 - mse: 20.4877 - val_loss: 5792.0093 - val_mse: 5792.0093\n",
      "Epoch 161/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 23.2662 - mse: 23.2662 - val_loss: 5792.1372 - val_mse: 5792.1372\n",
      "Epoch 162/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 28.0242 - mse: 28.0242 - val_loss: 5757.9937 - val_mse: 5757.9937\n",
      "Epoch 163/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 34.0046 - mse: 34.0046 - val_loss: 5784.7847 - val_mse: 5784.7847\n",
      "Epoch 164/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 43.8028 - mse: 43.8028 - val_loss: 5824.9585 - val_mse: 5824.9585\n",
      "Epoch 165/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 44.5265 - mse: 44.5265 - val_loss: 5810.4639 - val_mse: 5810.4639\n",
      "Epoch 166/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 37.9554 - mse: 37.9554 - val_loss: 5792.0376 - val_mse: 5792.0376\n",
      "Epoch 167/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 42.2449 - mse: 42.2449 - val_loss: 5784.8706 - val_mse: 5784.8706\n",
      "Epoch 168/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 39.8728 - mse: 39.8728 - val_loss: 5776.2803 - val_mse: 5776.2803\n",
      "Epoch 169/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 39.7124 - mse: 39.7124 - val_loss: 5788.8916 - val_mse: 5788.8916\n",
      "Epoch 170/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 46.8575 - mse: 46.8575 - val_loss: 5754.5425 - val_mse: 5754.5425\n",
      "Epoch 171/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 49.6558 - mse: 49.6558 - val_loss: 5806.7227 - val_mse: 5806.7227\n",
      "Epoch 172/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 59.7858 - mse: 59.7858 - val_loss: 5811.8560 - val_mse: 5811.8560\n",
      "Epoch 173/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 69.1277 - mse: 69.1277 - val_loss: 5835.3008 - val_mse: 5835.3008\n",
      "Epoch 174/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 60.8762 - mse: 60.8762 - val_loss: 5820.6694 - val_mse: 5820.6694\n",
      "Epoch 175/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 53.0452 - mse: 53.0452 - val_loss: 5797.6187 - val_mse: 5797.6187\n",
      "Epoch 176/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 42.2037 - mse: 42.2037 - val_loss: 5811.9805 - val_mse: 5811.9805\n",
      "Epoch 177/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 35.5682 - mse: 35.5682 - val_loss: 5770.6792 - val_mse: 5770.6792\n",
      "Epoch 178/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 28.2254 - mse: 28.2254 - val_loss: 5764.3101 - val_mse: 5764.3101\n",
      "Epoch 179/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 26.7347 - mse: 26.7347 - val_loss: 5789.2632 - val_mse: 5789.2632\n",
      "Epoch 180/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 29.6059 - mse: 29.6059 - val_loss: 5804.4131 - val_mse: 5804.4131\n",
      "Epoch 181/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 33.0403 - mse: 33.0403 - val_loss: 5816.7681 - val_mse: 5816.7681\n",
      "Epoch 182/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 28.8584 - mse: 28.8584 - val_loss: 5737.8496 - val_mse: 5737.8496\n",
      "Epoch 183/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 31.8769 - mse: 31.8769 - val_loss: 5804.5669 - val_mse: 5804.5669\n",
      "Epoch 184/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 39.5155 - mse: 39.5155 - val_loss: 5774.6196 - val_mse: 5774.6196\n",
      "Epoch 185/300\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 61.6140 - mse: 61.6140 - val_loss: 5730.7656 - val_mse: 5730.7656\n",
      "Epoch 186/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 52.8143 - mse: 52.8143 - val_loss: 5777.1328 - val_mse: 5777.1328\n",
      "Epoch 187/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 36.0849 - mse: 36.0849 - val_loss: 5841.4526 - val_mse: 5841.4526\n",
      "Epoch 188/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 30.6016 - mse: 30.6016 - val_loss: 5815.8706 - val_mse: 5815.8706\n",
      "Epoch 189/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 43.8822 - mse: 43.8822 - val_loss: 5841.6772 - val_mse: 5841.6772\n",
      "Epoch 190/300\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 32.9360 - mse: 32.9360 - val_loss: 5762.6616 - val_mse: 5762.6616\n",
      "Epoch 191/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 22.0856 - mse: 22.0856 - val_loss: 5808.0728 - val_mse: 5808.0728\n",
      "Epoch 192/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 18.3895 - mse: 18.3895 - val_loss: 5802.8872 - val_mse: 5802.8872\n",
      "Epoch 193/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 23.6996 - mse: 23.6996 - val_loss: 5804.3467 - val_mse: 5804.3467\n",
      "Epoch 194/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 16.9849 - mse: 16.9849 - val_loss: 5793.4746 - val_mse: 5793.4746\n",
      "Epoch 195/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 11.6605 - mse: 11.6605 - val_loss: 5771.1489 - val_mse: 5771.1489\n",
      "Epoch 196/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 14.4857 - mse: 14.4857 - val_loss: 5779.4297 - val_mse: 5779.4297\n",
      "Epoch 197/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 18.7071 - mse: 18.7071 - val_loss: 5860.1934 - val_mse: 5860.1934\n",
      "Epoch 198/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 20.6666 - mse: 20.6666 - val_loss: 5815.2686 - val_mse: 5815.2686\n",
      "Epoch 199/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 32.2497 - mse: 32.2497 - val_loss: 5829.7983 - val_mse: 5829.7983\n",
      "Epoch 200/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 30.3834 - mse: 30.3834 - val_loss: 5792.9312 - val_mse: 5792.9312\n",
      "Epoch 201/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 38.5396 - mse: 38.5396 - val_loss: 5757.6006 - val_mse: 5757.6006\n",
      "Epoch 202/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 30.4897 - mse: 30.4897 - val_loss: 5743.9092 - val_mse: 5743.9092\n",
      "Epoch 203/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 26.4316 - mse: 26.4316 - val_loss: 5788.0962 - val_mse: 5788.0962\n",
      "Epoch 204/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 31.3688 - mse: 31.3688 - val_loss: 5762.0723 - val_mse: 5762.0723\n",
      "Epoch 205/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 31.9054 - mse: 31.9054 - val_loss: 5821.7998 - val_mse: 5821.7998\n",
      "Epoch 206/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 38.4408 - mse: 38.4408 - val_loss: 5809.7329 - val_mse: 5809.7329\n",
      "Epoch 207/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 39.7428 - mse: 39.7428 - val_loss: 5799.1172 - val_mse: 5799.1172\n",
      "Epoch 208/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 32.0683 - mse: 32.0683 - val_loss: 5826.5093 - val_mse: 5826.5093\n",
      "Epoch 209/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 41.3876 - mse: 41.3876 - val_loss: 5762.4287 - val_mse: 5762.4287\n",
      "Epoch 210/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 53.7537 - mse: 53.7537 - val_loss: 5717.5479 - val_mse: 5717.5479\n",
      "Epoch 211/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 43.6495 - mse: 43.6495 - val_loss: 5895.4067 - val_mse: 5895.4067\n",
      "Epoch 212/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 45.6592 - mse: 45.6592 - val_loss: 5844.6001 - val_mse: 5844.6001\n",
      "Epoch 213/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 30.2954 - mse: 30.2954 - val_loss: 5780.6724 - val_mse: 5780.6724\n",
      "Epoch 214/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 25.6734 - mse: 25.6734 - val_loss: 5773.9111 - val_mse: 5773.9111\n",
      "Epoch 215/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 23.9868 - mse: 23.9868 - val_loss: 5805.9043 - val_mse: 5805.9043\n",
      "Epoch 216/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 27.3986 - mse: 27.3986 - val_loss: 5733.8179 - val_mse: 5733.8179\n",
      "Epoch 217/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 44.5834 - mse: 44.5834 - val_loss: 5810.0264 - val_mse: 5810.0264\n",
      "Epoch 218/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 36.5869 - mse: 36.5869 - val_loss: 5747.9106 - val_mse: 5747.9106\n",
      "Epoch 219/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 72.4141 - mse: 72.4141 - val_loss: 5709.7139 - val_mse: 5709.7139\n",
      "Epoch 220/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 69.9234 - mse: 69.9234 - val_loss: 5817.3105 - val_mse: 5817.3105\n",
      "Epoch 221/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 53.0221 - mse: 53.0221 - val_loss: 5777.2949 - val_mse: 5777.2949\n",
      "Epoch 222/300\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 30.5385 - mse: 30.5385 - val_loss: 5850.5952 - val_mse: 5850.5952\n",
      "Epoch 223/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 24.6945 - mse: 24.6945 - val_loss: 5757.3042 - val_mse: 5757.3042\n",
      "Epoch 224/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 20.2144 - mse: 20.2144 - val_loss: 5838.4683 - val_mse: 5838.4683\n",
      "Epoch 225/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 21.7141 - mse: 21.7141 - val_loss: 5746.4727 - val_mse: 5746.4727\n",
      "Epoch 226/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 22.8160 - mse: 22.8160 - val_loss: 5754.6191 - val_mse: 5754.6191\n",
      "Epoch 227/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 25.2531 - mse: 25.2531 - val_loss: 5803.9292 - val_mse: 5803.9292\n",
      "Epoch 228/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 20.7658 - mse: 20.7658 - val_loss: 5812.9409 - val_mse: 5812.9409\n",
      "Epoch 229/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 30.5370 - mse: 30.5370 - val_loss: 5835.8628 - val_mse: 5835.8628\n",
      "Epoch 230/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 28.2341 - mse: 28.2341 - val_loss: 5759.9077 - val_mse: 5759.9077\n",
      "Epoch 231/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 19.9103 - mse: 19.9103 - val_loss: 5801.8784 - val_mse: 5801.8784\n",
      "Epoch 232/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 32.5526 - mse: 32.5526 - val_loss: 5704.7417 - val_mse: 5704.7417\n",
      "Epoch 233/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 36.9613 - mse: 36.9613 - val_loss: 5795.7148 - val_mse: 5795.7148\n",
      "Epoch 234/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 30.1187 - mse: 30.1187 - val_loss: 5642.2334 - val_mse: 5642.2334\n",
      "Epoch 235/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 27.8295 - mse: 27.8295 - val_loss: 5758.0283 - val_mse: 5758.0283\n",
      "Epoch 236/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 26.5327 - mse: 26.5327 - val_loss: 5713.9683 - val_mse: 5713.9683\n",
      "Epoch 237/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 30.6812 - mse: 30.6812 - val_loss: 5813.3745 - val_mse: 5813.3745\n",
      "Epoch 238/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 37.3182 - mse: 37.3182 - val_loss: 5659.0088 - val_mse: 5659.0088\n",
      "Epoch 239/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 38.7366 - mse: 38.7366 - val_loss: 5858.6851 - val_mse: 5858.6851\n",
      "Epoch 240/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 31.2748 - mse: 31.2748 - val_loss: 5612.5542 - val_mse: 5612.5542\n",
      "Epoch 241/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 31.2278 - mse: 31.2278 - val_loss: 5770.4004 - val_mse: 5770.4004\n",
      "Epoch 242/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 28.3023 - mse: 28.3023 - val_loss: 5666.8457 - val_mse: 5666.8457\n",
      "Epoch 243/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 25.6868 - mse: 25.6868 - val_loss: 5812.2217 - val_mse: 5812.2217\n",
      "Epoch 244/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 20.0461 - mse: 20.0461 - val_loss: 5795.0244 - val_mse: 5795.0244\n",
      "Epoch 245/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 21.2429 - mse: 21.2429 - val_loss: 5710.1919 - val_mse: 5710.1919\n",
      "Epoch 246/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 22.1316 - mse: 22.1316 - val_loss: 5689.8540 - val_mse: 5689.8540\n",
      "Epoch 247/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 31.9148 - mse: 31.9148 - val_loss: 5770.3594 - val_mse: 5770.3594\n",
      "Epoch 248/300\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 40.1147 - mse: 40.1147 - val_loss: 5792.6938 - val_mse: 5792.6938\n",
      "Epoch 249/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 33.9495 - mse: 33.9495 - val_loss: 5677.4756 - val_mse: 5677.4756\n",
      "Epoch 250/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 39.9880 - mse: 39.9880 - val_loss: 5712.3926 - val_mse: 5712.3926\n",
      "Epoch 251/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 38.7813 - mse: 38.7813 - val_loss: 5782.2388 - val_mse: 5782.2388\n",
      "Epoch 252/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 31.2614 - mse: 31.2614 - val_loss: 5743.0376 - val_mse: 5743.0376\n",
      "Epoch 253/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 29.2359 - mse: 29.2359 - val_loss: 5746.9136 - val_mse: 5746.9136\n",
      "Epoch 254/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 27.1716 - mse: 27.1716 - val_loss: 5716.9155 - val_mse: 5716.9155\n",
      "Epoch 255/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 28.4027 - mse: 28.4027 - val_loss: 5728.9370 - val_mse: 5728.9370\n",
      "Epoch 256/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 29.9100 - mse: 29.9100 - val_loss: 5762.2251 - val_mse: 5762.2251\n",
      "Epoch 257/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 34.6052 - mse: 34.6052 - val_loss: 5720.8276 - val_mse: 5720.8276\n",
      "Epoch 258/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 34.1346 - mse: 34.1346 - val_loss: 5738.3481 - val_mse: 5738.3481\n",
      "Epoch 259/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 35.1651 - mse: 35.1651 - val_loss: 5713.5518 - val_mse: 5713.5518\n",
      "Epoch 260/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 36.7107 - mse: 36.7107 - val_loss: 5655.8018 - val_mse: 5655.8018\n",
      "Epoch 261/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 40.7557 - mse: 40.7557 - val_loss: 5630.1792 - val_mse: 5630.1792\n",
      "Epoch 262/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 44.2926 - mse: 44.2926 - val_loss: 5705.1934 - val_mse: 5705.1934\n",
      "Epoch 263/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 49.5068 - mse: 49.5068 - val_loss: 5680.9409 - val_mse: 5680.9409\n",
      "Epoch 264/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 40.1225 - mse: 40.1225 - val_loss: 5696.5396 - val_mse: 5696.5396\n",
      "Epoch 265/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 29.8303 - mse: 29.8303 - val_loss: 5728.4868 - val_mse: 5728.4868\n",
      "Epoch 266/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 24.8121 - mse: 24.8121 - val_loss: 5707.5674 - val_mse: 5707.5674\n",
      "Epoch 267/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 33.5070 - mse: 33.5070 - val_loss: 5729.9219 - val_mse: 5729.9219\n",
      "Epoch 268/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 28.6453 - mse: 28.6453 - val_loss: 5747.2236 - val_mse: 5747.2236\n",
      "Epoch 269/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 34.5854 - mse: 34.5854 - val_loss: 5709.6123 - val_mse: 5709.6123\n",
      "Epoch 270/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 25.8716 - mse: 25.8716 - val_loss: 5711.0098 - val_mse: 5711.0098\n",
      "Epoch 271/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 24.0357 - mse: 24.0357 - val_loss: 5737.3906 - val_mse: 5737.3906\n",
      "Epoch 272/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 29.6423 - mse: 29.6423 - val_loss: 5658.7456 - val_mse: 5658.7456\n",
      "Epoch 273/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 25.9458 - mse: 25.9458 - val_loss: 5737.9585 - val_mse: 5737.9585\n",
      "Epoch 274/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 24.6653 - mse: 24.6653 - val_loss: 5670.4678 - val_mse: 5670.4678\n",
      "Epoch 275/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 24.9492 - mse: 24.9492 - val_loss: 5694.2295 - val_mse: 5694.2295\n",
      "Epoch 276/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 28.1476 - mse: 28.1476 - val_loss: 5689.8765 - val_mse: 5689.8765\n",
      "Epoch 277/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 35.9509 - mse: 35.9509 - val_loss: 5671.9390 - val_mse: 5671.9390\n",
      "Epoch 278/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 35.1344 - mse: 35.1344 - val_loss: 5762.0234 - val_mse: 5762.0234\n",
      "Epoch 279/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 28.9989 - mse: 28.9989 - val_loss: 5789.3223 - val_mse: 5789.3223\n",
      "Epoch 280/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 30.3518 - mse: 30.3518 - val_loss: 5655.1392 - val_mse: 5655.1392\n",
      "Epoch 281/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 30.4129 - mse: 30.4129 - val_loss: 5705.4399 - val_mse: 5705.4399\n",
      "Epoch 282/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 33.1828 - mse: 33.1828 - val_loss: 5734.3242 - val_mse: 5734.3242\n",
      "Epoch 283/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 27.2078 - mse: 27.2078 - val_loss: 5792.1333 - val_mse: 5792.1333\n",
      "Epoch 284/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 27.3865 - mse: 27.3865 - val_loss: 5667.8950 - val_mse: 5667.8950\n",
      "Epoch 285/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 30.4158 - mse: 30.4158 - val_loss: 5720.8013 - val_mse: 5720.8013\n",
      "Epoch 286/300\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 29.5744 - mse: 29.5744 - val_loss: 5731.9824 - val_mse: 5731.9824\n",
      "Epoch 287/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 25.8407 - mse: 25.8407 - val_loss: 5698.1968 - val_mse: 5698.1968\n",
      "Epoch 288/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 25.7422 - mse: 25.7422 - val_loss: 5781.1182 - val_mse: 5781.1182\n",
      "Epoch 289/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 25.1179 - mse: 25.1179 - val_loss: 5630.9287 - val_mse: 5630.9287\n",
      "Epoch 290/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 32.8070 - mse: 32.8070 - val_loss: 5719.2178 - val_mse: 5719.2178\n",
      "Epoch 291/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 35.2931 - mse: 35.2931 - val_loss: 5648.2310 - val_mse: 5648.2310\n",
      "Epoch 292/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 38.1794 - mse: 38.1794 - val_loss: 5722.1587 - val_mse: 5722.1587\n",
      "Epoch 293/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 37.1011 - mse: 37.1011 - val_loss: 5628.7227 - val_mse: 5628.7227\n",
      "Epoch 294/300\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 28.4525 - mse: 28.4525 - val_loss: 5726.5728 - val_mse: 5726.5728\n",
      "Epoch 295/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.8045 - mse: 20.8045 - val_loss: 5655.4380 - val_mse: 5655.4380\n",
      "Epoch 296/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 21.0527 - mse: 21.0527 - val_loss: 5686.9082 - val_mse: 5686.9082\n",
      "Epoch 297/300\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 24.3564 - mse: 24.3564 - val_loss: 5584.2808 - val_mse: 5584.2808\n",
      "Epoch 298/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 30.3028 - mse: 30.3028 - val_loss: 5788.9624 - val_mse: 5788.9624\n",
      "Epoch 299/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 31.1327 - mse: 31.1327 - val_loss: 5625.9604 - val_mse: 5625.9604\n",
      "Epoch 300/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 33.4009 - mse: 33.4009 - val_loss: 5642.8936 - val_mse: 5642.8936\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x191ab4a7e80>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.fit(x_train, y_train, batch_size=16, epochs=300, validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## app price <250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>id_property</th>\n",
       "      <th>beds_basic</th>\n",
       "      <th>amount</th>\n",
       "      <th>area</th>\n",
       "      <th>floor</th>\n",
       "      <th>category</th>\n",
       "      <th>city</th>\n",
       "      <th>beds_additional</th>\n",
       "      <th>garden</th>\n",
       "      <th>...</th>\n",
       "      <th>hot_water_supply</th>\n",
       "      <th>no_smoking_rooms</th>\n",
       "      <th>in_mini_soccer</th>\n",
       "      <th>special_business</th>\n",
       "      <th>special_groups</th>\n",
       "      <th>unit_bedroom_mosquito_net</th>\n",
       "      <th>mosquito_net</th>\n",
       "      <th>property_internet_location</th>\n",
       "      <th>location_turistcomplex</th>\n",
       "      <th>in_food_local_speciality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24588</td>\n",
       "      <td>10043</td>\n",
       "      <td>4</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1.200568</td>\n",
       "      <td>1.821022</td>\n",
       "      <td>-0.159881</td>\n",
       "      <td>-0.448308</td>\n",
       "      <td>1.114105</td>\n",
       "      <td>1.223997</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.04695</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.121988</td>\n",
       "      <td>-0.054233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24589</td>\n",
       "      <td>10043</td>\n",
       "      <td>4</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1.200568</td>\n",
       "      <td>0.598643</td>\n",
       "      <td>-0.159881</td>\n",
       "      <td>-0.448308</td>\n",
       "      <td>1.114105</td>\n",
       "      <td>1.223997</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.04695</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.121988</td>\n",
       "      <td>-0.054233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24590</td>\n",
       "      <td>10043</td>\n",
       "      <td>4</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1.200568</td>\n",
       "      <td>-0.623736</td>\n",
       "      <td>-0.159881</td>\n",
       "      <td>-0.448308</td>\n",
       "      <td>-1.105967</td>\n",
       "      <td>1.223997</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.04695</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.121988</td>\n",
       "      <td>-0.054233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24593</td>\n",
       "      <td>10046</td>\n",
       "      <td>4</td>\n",
       "      <td>105.00</td>\n",
       "      <td>-0.150958</td>\n",
       "      <td>-0.623736</td>\n",
       "      <td>-0.159881</td>\n",
       "      <td>-0.448308</td>\n",
       "      <td>-1.105967</td>\n",
       "      <td>1.223997</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.04695</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.121988</td>\n",
       "      <td>-0.054233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24594</td>\n",
       "      <td>9098</td>\n",
       "      <td>4</td>\n",
       "      <td>120.00</td>\n",
       "      <td>0.194113</td>\n",
       "      <td>-0.623736</td>\n",
       "      <td>-0.159881</td>\n",
       "      <td>0.145470</td>\n",
       "      <td>0.004069</td>\n",
       "      <td>1.223997</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.04695</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.121988</td>\n",
       "      <td>-0.054233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1359</th>\n",
       "      <td>8166</td>\n",
       "      <td>3559</td>\n",
       "      <td>6</td>\n",
       "      <td>78.26</td>\n",
       "      <td>0.625451</td>\n",
       "      <td>-0.623736</td>\n",
       "      <td>-3.952536</td>\n",
       "      <td>-0.448308</td>\n",
       "      <td>1.114105</td>\n",
       "      <td>1.223997</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.04695</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.121988</td>\n",
       "      <td>-0.054233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1360</th>\n",
       "      <td>8175</td>\n",
       "      <td>3564</td>\n",
       "      <td>4</td>\n",
       "      <td>80.00</td>\n",
       "      <td>0.050333</td>\n",
       "      <td>1.821022</td>\n",
       "      <td>-2.056208</td>\n",
       "      <td>-0.448308</td>\n",
       "      <td>-1.105967</td>\n",
       "      <td>-0.816996</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.04695</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.121988</td>\n",
       "      <td>-0.054233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361</th>\n",
       "      <td>8176</td>\n",
       "      <td>3564</td>\n",
       "      <td>2</td>\n",
       "      <td>37.00</td>\n",
       "      <td>-1.042390</td>\n",
       "      <td>1.821022</td>\n",
       "      <td>-2.056208</td>\n",
       "      <td>-0.448308</td>\n",
       "      <td>-1.105967</td>\n",
       "      <td>-0.816996</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.04695</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.121988</td>\n",
       "      <td>-0.054233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1362</th>\n",
       "      <td>24567</td>\n",
       "      <td>10030</td>\n",
       "      <td>4</td>\n",
       "      <td>80.00</td>\n",
       "      <td>1.085545</td>\n",
       "      <td>0.598643</td>\n",
       "      <td>-0.159881</td>\n",
       "      <td>1.135099</td>\n",
       "      <td>1.114105</td>\n",
       "      <td>1.223997</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.04695</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.121988</td>\n",
       "      <td>-0.054233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1363</th>\n",
       "      <td>24575</td>\n",
       "      <td>10039</td>\n",
       "      <td>6</td>\n",
       "      <td>220.00</td>\n",
       "      <td>3.443527</td>\n",
       "      <td>-0.623736</td>\n",
       "      <td>1.736446</td>\n",
       "      <td>-0.151419</td>\n",
       "      <td>-1.105967</td>\n",
       "      <td>1.223997</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.04695</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.121988</td>\n",
       "      <td>-0.054233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1287 rows × 251 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  id_property  beds_basic  amount      area     floor  category  \\\n",
       "0     24588        10043           4  130.00  1.200568  1.821022 -0.159881   \n",
       "1     24589        10043           4  130.00  1.200568  0.598643 -0.159881   \n",
       "2     24590        10043           4  130.00  1.200568 -0.623736 -0.159881   \n",
       "3     24593        10046           4  105.00 -0.150958 -0.623736 -0.159881   \n",
       "4     24594         9098           4  120.00  0.194113 -0.623736 -0.159881   \n",
       "...     ...          ...         ...     ...       ...       ...       ...   \n",
       "1359   8166         3559           6   78.26  0.625451 -0.623736 -3.952536   \n",
       "1360   8175         3564           4   80.00  0.050333  1.821022 -2.056208   \n",
       "1361   8176         3564           2   37.00 -1.042390  1.821022 -2.056208   \n",
       "1362  24567        10030           4   80.00  1.085545  0.598643 -0.159881   \n",
       "1363  24575        10039           6  220.00  3.443527 -0.623736  1.736446   \n",
       "\n",
       "          city  beds_additional    garden  ...  hot_water_supply  \\\n",
       "0    -0.448308         1.114105  1.223997  ...          -0.03832   \n",
       "1    -0.448308         1.114105  1.223997  ...          -0.03832   \n",
       "2    -0.448308        -1.105967  1.223997  ...          -0.03832   \n",
       "3    -0.448308        -1.105967  1.223997  ...          -0.03832   \n",
       "4     0.145470         0.004069  1.223997  ...          -0.03832   \n",
       "...        ...              ...       ...  ...               ...   \n",
       "1359 -0.448308         1.114105  1.223997  ...          -0.03832   \n",
       "1360 -0.448308        -1.105967 -0.816996  ...          -0.03832   \n",
       "1361 -0.448308        -1.105967 -0.816996  ...          -0.03832   \n",
       "1362  1.135099         1.114105  1.223997  ...          -0.03832   \n",
       "1363 -0.151419        -1.105967  1.223997  ...          -0.03832   \n",
       "\n",
       "      no_smoking_rooms  in_mini_soccer  special_business  special_groups  \\\n",
       "0            -0.054233       -0.027086          -0.03832       -0.027086   \n",
       "1            -0.054233       -0.027086          -0.03832       -0.027086   \n",
       "2            -0.054233       -0.027086          -0.03832       -0.027086   \n",
       "3            -0.054233       -0.027086          -0.03832       -0.027086   \n",
       "4            -0.054233       -0.027086          -0.03832       -0.027086   \n",
       "...                ...             ...               ...             ...   \n",
       "1359         -0.054233       -0.027086          -0.03832       -0.027086   \n",
       "1360         -0.054233       -0.027086          -0.03832       -0.027086   \n",
       "1361         -0.054233       -0.027086          -0.03832       -0.027086   \n",
       "1362         -0.054233       -0.027086          -0.03832       -0.027086   \n",
       "1363         -0.054233       -0.027086          -0.03832       -0.027086   \n",
       "\n",
       "      unit_bedroom_mosquito_net  mosquito_net  property_internet_location  \\\n",
       "0                     -0.054233      -0.04695                   -0.027086   \n",
       "1                     -0.054233      -0.04695                   -0.027086   \n",
       "2                     -0.054233      -0.04695                   -0.027086   \n",
       "3                     -0.054233      -0.04695                   -0.027086   \n",
       "4                     -0.054233      -0.04695                   -0.027086   \n",
       "...                         ...           ...                         ...   \n",
       "1359                  -0.054233      -0.04695                   -0.027086   \n",
       "1360                  -0.054233      -0.04695                   -0.027086   \n",
       "1361                  -0.054233      -0.04695                   -0.027086   \n",
       "1362                  -0.054233      -0.04695                   -0.027086   \n",
       "1363                  -0.054233      -0.04695                   -0.027086   \n",
       "\n",
       "      location_turistcomplex  in_food_local_speciality  \n",
       "0                  -0.121988                 -0.054233  \n",
       "1                  -0.121988                 -0.054233  \n",
       "2                  -0.121988                 -0.054233  \n",
       "3                  -0.121988                 -0.054233  \n",
       "4                  -0.121988                 -0.054233  \n",
       "...                      ...                       ...  \n",
       "1359               -0.121988                 -0.054233  \n",
       "1360               -0.121988                 -0.054233  \n",
       "1361               -0.121988                 -0.054233  \n",
       "1362               -0.121988                 -0.054233  \n",
       "1363               -0.121988                 -0.054233  \n",
       "\n",
       "[1287 rows x 251 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df[df[\"amount\"]<=250]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>id_property</th>\n",
       "      <th>beds_basic</th>\n",
       "      <th>amount</th>\n",
       "      <th>area</th>\n",
       "      <th>floor</th>\n",
       "      <th>category</th>\n",
       "      <th>city</th>\n",
       "      <th>beds_additional</th>\n",
       "      <th>garden</th>\n",
       "      <th>...</th>\n",
       "      <th>hot_water_supply</th>\n",
       "      <th>no_smoking_rooms</th>\n",
       "      <th>in_mini_soccer</th>\n",
       "      <th>special_business</th>\n",
       "      <th>special_groups</th>\n",
       "      <th>unit_bedroom_mosquito_net</th>\n",
       "      <th>mosquito_net</th>\n",
       "      <th>property_internet_location</th>\n",
       "      <th>location_turistcomplex</th>\n",
       "      <th>in_food_local_speciality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24588</td>\n",
       "      <td>10043</td>\n",
       "      <td>4</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1.200568</td>\n",
       "      <td>1.821022</td>\n",
       "      <td>-0.159881</td>\n",
       "      <td>-0.448308</td>\n",
       "      <td>1.114105</td>\n",
       "      <td>1.223997</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.04695</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.121988</td>\n",
       "      <td>-0.054233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24589</td>\n",
       "      <td>10043</td>\n",
       "      <td>4</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1.200568</td>\n",
       "      <td>0.598643</td>\n",
       "      <td>-0.159881</td>\n",
       "      <td>-0.448308</td>\n",
       "      <td>1.114105</td>\n",
       "      <td>1.223997</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.04695</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.121988</td>\n",
       "      <td>-0.054233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24590</td>\n",
       "      <td>10043</td>\n",
       "      <td>4</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1.200568</td>\n",
       "      <td>-0.623736</td>\n",
       "      <td>-0.159881</td>\n",
       "      <td>-0.448308</td>\n",
       "      <td>-1.105967</td>\n",
       "      <td>1.223997</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.04695</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.121988</td>\n",
       "      <td>-0.054233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24593</td>\n",
       "      <td>10046</td>\n",
       "      <td>4</td>\n",
       "      <td>105.0</td>\n",
       "      <td>-0.150958</td>\n",
       "      <td>-0.623736</td>\n",
       "      <td>-0.159881</td>\n",
       "      <td>-0.448308</td>\n",
       "      <td>-1.105967</td>\n",
       "      <td>1.223997</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.04695</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.121988</td>\n",
       "      <td>-0.054233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24594</td>\n",
       "      <td>9098</td>\n",
       "      <td>4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.194113</td>\n",
       "      <td>-0.623736</td>\n",
       "      <td>-0.159881</td>\n",
       "      <td>0.145470</td>\n",
       "      <td>0.004069</td>\n",
       "      <td>1.223997</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.04695</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.121988</td>\n",
       "      <td>-0.054233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>24512</td>\n",
       "      <td>8028</td>\n",
       "      <td>4</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1.488127</td>\n",
       "      <td>1.821022</td>\n",
       "      <td>-0.159881</td>\n",
       "      <td>-0.448308</td>\n",
       "      <td>-1.105967</td>\n",
       "      <td>1.223997</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.04695</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.121988</td>\n",
       "      <td>-0.054233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>24513</td>\n",
       "      <td>10013</td>\n",
       "      <td>4</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.194113</td>\n",
       "      <td>0.598643</td>\n",
       "      <td>-0.159881</td>\n",
       "      <td>-0.448308</td>\n",
       "      <td>0.004069</td>\n",
       "      <td>-0.816996</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.04695</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.121988</td>\n",
       "      <td>-0.054233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>24516</td>\n",
       "      <td>10014</td>\n",
       "      <td>4</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-0.237225</td>\n",
       "      <td>-0.623736</td>\n",
       "      <td>-0.159881</td>\n",
       "      <td>1.431988</td>\n",
       "      <td>-1.105967</td>\n",
       "      <td>-0.816996</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.04695</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.121988</td>\n",
       "      <td>-0.054233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>8175</td>\n",
       "      <td>3564</td>\n",
       "      <td>4</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.050333</td>\n",
       "      <td>1.821022</td>\n",
       "      <td>-2.056208</td>\n",
       "      <td>-0.448308</td>\n",
       "      <td>-1.105967</td>\n",
       "      <td>-0.816996</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.04695</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.121988</td>\n",
       "      <td>-0.054233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>24567</td>\n",
       "      <td>10030</td>\n",
       "      <td>4</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.085545</td>\n",
       "      <td>0.598643</td>\n",
       "      <td>-0.159881</td>\n",
       "      <td>1.135099</td>\n",
       "      <td>1.114105</td>\n",
       "      <td>1.223997</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.04695</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.121988</td>\n",
       "      <td>-0.054233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>497 rows × 251 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  id_property  beds_basic  amount      area     floor  category  \\\n",
       "0    24588        10043           4   130.0  1.200568  1.821022 -0.159881   \n",
       "1    24589        10043           4   130.0  1.200568  0.598643 -0.159881   \n",
       "2    24590        10043           4   130.0  1.200568 -0.623736 -0.159881   \n",
       "3    24593        10046           4   105.0 -0.150958 -0.623736 -0.159881   \n",
       "4    24594         9098           4   120.0  0.194113 -0.623736 -0.159881   \n",
       "..     ...          ...         ...     ...       ...       ...       ...   \n",
       "492  24512         8028           4   160.0  1.488127  1.821022 -0.159881   \n",
       "493  24513        10013           4    85.0  0.194113  0.598643 -0.159881   \n",
       "494  24516        10014           4    95.0 -0.237225 -0.623736 -0.159881   \n",
       "495   8175         3564           4    80.0  0.050333  1.821022 -2.056208   \n",
       "496  24567        10030           4    80.0  1.085545  0.598643 -0.159881   \n",
       "\n",
       "         city  beds_additional    garden  ...  hot_water_supply  \\\n",
       "0   -0.448308         1.114105  1.223997  ...          -0.03832   \n",
       "1   -0.448308         1.114105  1.223997  ...          -0.03832   \n",
       "2   -0.448308        -1.105967  1.223997  ...          -0.03832   \n",
       "3   -0.448308        -1.105967  1.223997  ...          -0.03832   \n",
       "4    0.145470         0.004069  1.223997  ...          -0.03832   \n",
       "..        ...              ...       ...  ...               ...   \n",
       "492 -0.448308        -1.105967  1.223997  ...          -0.03832   \n",
       "493 -0.448308         0.004069 -0.816996  ...          -0.03832   \n",
       "494  1.431988        -1.105967 -0.816996  ...          -0.03832   \n",
       "495 -0.448308        -1.105967 -0.816996  ...          -0.03832   \n",
       "496  1.135099         1.114105  1.223997  ...          -0.03832   \n",
       "\n",
       "     no_smoking_rooms  in_mini_soccer  special_business  special_groups  \\\n",
       "0           -0.054233       -0.027086          -0.03832       -0.027086   \n",
       "1           -0.054233       -0.027086          -0.03832       -0.027086   \n",
       "2           -0.054233       -0.027086          -0.03832       -0.027086   \n",
       "3           -0.054233       -0.027086          -0.03832       -0.027086   \n",
       "4           -0.054233       -0.027086          -0.03832       -0.027086   \n",
       "..                ...             ...               ...             ...   \n",
       "492         -0.054233       -0.027086          -0.03832       -0.027086   \n",
       "493         -0.054233       -0.027086          -0.03832       -0.027086   \n",
       "494         -0.054233       -0.027086          -0.03832       -0.027086   \n",
       "495         -0.054233       -0.027086          -0.03832       -0.027086   \n",
       "496         -0.054233       -0.027086          -0.03832       -0.027086   \n",
       "\n",
       "     unit_bedroom_mosquito_net  mosquito_net  property_internet_location  \\\n",
       "0                    -0.054233      -0.04695                   -0.027086   \n",
       "1                    -0.054233      -0.04695                   -0.027086   \n",
       "2                    -0.054233      -0.04695                   -0.027086   \n",
       "3                    -0.054233      -0.04695                   -0.027086   \n",
       "4                    -0.054233      -0.04695                   -0.027086   \n",
       "..                         ...           ...                         ...   \n",
       "492                  -0.054233      -0.04695                   -0.027086   \n",
       "493                  -0.054233      -0.04695                   -0.027086   \n",
       "494                  -0.054233      -0.04695                   -0.027086   \n",
       "495                  -0.054233      -0.04695                   -0.027086   \n",
       "496                  -0.054233      -0.04695                   -0.027086   \n",
       "\n",
       "     location_turistcomplex  in_food_local_speciality  \n",
       "0                 -0.121988                 -0.054233  \n",
       "1                 -0.121988                 -0.054233  \n",
       "2                 -0.121988                 -0.054233  \n",
       "3                 -0.121988                 -0.054233  \n",
       "4                 -0.121988                 -0.054233  \n",
       "..                      ...                       ...  \n",
       "492               -0.121988                 -0.054233  \n",
       "493               -0.121988                 -0.054233  \n",
       "494               -0.121988                 -0.054233  \n",
       "495               -0.121988                 -0.054233  \n",
       "496               -0.121988                 -0.054233  \n",
       "\n",
       "[497 rows x 251 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df24=df2[df2[\"beds_basic\"]==4]\n",
    "df24.reset_index(inplace=True,drop=True)\n",
    "df24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df24.iloc[:,4:]\n",
    "Y=df24.loc[:,\"amount\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([19., 90., 96., 86., 28., 18., 18.,  4.,  5.,  8.]),\n",
       " array([ 50.,  68.,  86., 104., 122., 140., 158., 176., 194., 212., 230.]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(X, Y)\n",
    "plt.hist(y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107.21798387096773, 109.7736, 34.05973040127924, 29.892652414717176)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train2.mean(), y_test2.mean(),y_train2.std(),y_test2.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = tf.keras.models.Sequential()\n",
    "model_2.add(tf.keras.Input(shape=(247,)))\n",
    "\n",
    "model_2.add(tf.keras.layers.Dense(128, activation=\"relu\"))\n",
    "\n",
    "model_2.add(tf.keras.layers.Dense(1))\n",
    "model_2.compile(loss=\"mse\", optimizer=tf.keras.optimizers.Adam(learning_rate=0.003), metrics=[\"mse\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "24/24 [==============================] - 1s 12ms/step - loss: 11702.1934 - mse: 11702.1934 - val_loss: 10557.2266 - val_mse: 10557.2266\n",
      "Epoch 2/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 8431.4854 - mse: 8431.4854 - val_loss: 6625.6030 - val_mse: 6625.6030\n",
      "Epoch 3/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4448.5342 - mse: 4448.5342 - val_loss: 2889.6531 - val_mse: 2889.6531\n",
      "Epoch 4/300\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1596.1791 - mse: 1596.1791 - val_loss: 1025.8611 - val_mse: 1025.8611\n",
      "Epoch 5/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 639.6410 - mse: 639.6410 - val_loss: 643.9739 - val_mse: 643.9739\n",
      "Epoch 6/300\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 464.1593 - mse: 464.1593 - val_loss: 525.0016 - val_mse: 525.0016\n",
      "Epoch 7/300\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 375.6136 - mse: 375.6136 - val_loss: 460.3702 - val_mse: 460.3702\n",
      "Epoch 8/300\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 320.7601 - mse: 320.7601 - val_loss: 392.5745 - val_mse: 392.5745\n",
      "Epoch 9/300\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 276.2238 - mse: 276.2238 - val_loss: 354.6207 - val_mse: 354.6207\n",
      "Epoch 10/300\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 241.5879 - mse: 241.5879 - val_loss: 320.7220 - val_mse: 320.7220\n",
      "Epoch 11/300\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 213.2773 - mse: 213.2773 - val_loss: 291.3496 - val_mse: 291.3496\n",
      "Epoch 12/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 190.9211 - mse: 190.9211 - val_loss: 265.6287 - val_mse: 265.6287\n",
      "Epoch 13/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 172.8613 - mse: 172.8613 - val_loss: 244.6535 - val_mse: 244.6535\n",
      "Epoch 14/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 157.7857 - mse: 157.7857 - val_loss: 236.6157 - val_mse: 236.6157\n",
      "Epoch 15/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 141.5364 - mse: 141.5364 - val_loss: 229.7850 - val_mse: 229.7850\n",
      "Epoch 16/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 131.6165 - mse: 131.6165 - val_loss: 220.5499 - val_mse: 220.5499\n",
      "Epoch 17/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 118.7494 - mse: 118.7494 - val_loss: 212.3964 - val_mse: 212.3964\n",
      "Epoch 18/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 110.0444 - mse: 110.0444 - val_loss: 207.9790 - val_mse: 207.9790\n",
      "Epoch 19/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 103.5309 - mse: 103.5309 - val_loss: 199.4828 - val_mse: 199.4828\n",
      "Epoch 20/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 95.2416 - mse: 95.2416 - val_loss: 196.5746 - val_mse: 196.5746\n",
      "Epoch 21/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 90.1282 - mse: 90.1282 - val_loss: 195.7085 - val_mse: 195.7085\n",
      "Epoch 22/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 83.5625 - mse: 83.5625 - val_loss: 191.3060 - val_mse: 191.3060\n",
      "Epoch 23/300\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 78.7205 - mse: 78.7205 - val_loss: 188.0693 - val_mse: 188.0693\n",
      "Epoch 24/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 74.5173 - mse: 74.5173 - val_loss: 185.7261 - val_mse: 185.7261\n",
      "Epoch 25/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 70.4482 - mse: 70.4482 - val_loss: 181.4373 - val_mse: 181.4373\n",
      "Epoch 26/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 65.8442 - mse: 65.8442 - val_loss: 180.7065 - val_mse: 180.7065\n",
      "Epoch 27/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 63.1893 - mse: 63.1893 - val_loss: 177.4549 - val_mse: 177.4549\n",
      "Epoch 28/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 59.1681 - mse: 59.1681 - val_loss: 178.4625 - val_mse: 178.4625\n",
      "Epoch 29/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 55.5749 - mse: 55.5749 - val_loss: 174.8694 - val_mse: 174.8694\n",
      "Epoch 30/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 52.8745 - mse: 52.8745 - val_loss: 173.8978 - val_mse: 173.8978\n",
      "Epoch 31/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 52.3604 - mse: 52.3604 - val_loss: 174.7614 - val_mse: 174.7614\n",
      "Epoch 32/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 48.6982 - mse: 48.6982 - val_loss: 172.2831 - val_mse: 172.2831\n",
      "Epoch 33/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 44.6148 - mse: 44.6148 - val_loss: 172.6671 - val_mse: 172.6671\n",
      "Epoch 34/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 43.3656 - mse: 43.3656 - val_loss: 169.9914 - val_mse: 169.9914\n",
      "Epoch 35/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 41.8654 - mse: 41.8654 - val_loss: 170.9821 - val_mse: 170.9821\n",
      "Epoch 36/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 38.9657 - mse: 38.9657 - val_loss: 169.5492 - val_mse: 169.5492\n",
      "Epoch 37/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 36.9340 - mse: 36.9340 - val_loss: 167.9344 - val_mse: 167.9344\n",
      "Epoch 38/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 35.6497 - mse: 35.6497 - val_loss: 175.6664 - val_mse: 175.6664\n",
      "Epoch 39/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 34.5382 - mse: 34.5382 - val_loss: 168.5781 - val_mse: 168.5781\n",
      "Epoch 40/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 31.7669 - mse: 31.7669 - val_loss: 166.5495 - val_mse: 166.5495\n",
      "Epoch 41/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 30.0532 - mse: 30.0532 - val_loss: 163.7174 - val_mse: 163.7174\n",
      "Epoch 42/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 28.1221 - mse: 28.1221 - val_loss: 164.5916 - val_mse: 164.5916\n",
      "Epoch 43/300\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 28.0334 - mse: 28.0334 - val_loss: 162.8480 - val_mse: 162.8480\n",
      "Epoch 44/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 26.7914 - mse: 26.7914 - val_loss: 167.3683 - val_mse: 167.3683\n",
      "Epoch 45/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 26.0391 - mse: 26.0391 - val_loss: 164.5726 - val_mse: 164.5726\n",
      "Epoch 46/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 24.9187 - mse: 24.9187 - val_loss: 162.2353 - val_mse: 162.2353\n",
      "Epoch 47/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 22.9114 - mse: 22.9114 - val_loss: 162.8094 - val_mse: 162.8094\n",
      "Epoch 48/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 22.1548 - mse: 22.1548 - val_loss: 167.2949 - val_mse: 167.2949\n",
      "Epoch 49/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 20.8379 - mse: 20.8379 - val_loss: 160.7448 - val_mse: 160.7448\n",
      "Epoch 50/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 19.3008 - mse: 19.3008 - val_loss: 159.5627 - val_mse: 159.5627\n",
      "Epoch 51/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 17.5307 - mse: 17.5307 - val_loss: 163.2890 - val_mse: 163.2890\n",
      "Epoch 52/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 20.0910 - mse: 20.0910 - val_loss: 164.3863 - val_mse: 164.3863\n",
      "Epoch 53/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 20.3733 - mse: 20.3733 - val_loss: 159.5868 - val_mse: 159.5868\n",
      "Epoch 54/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 18.7824 - mse: 18.7824 - val_loss: 165.0262 - val_mse: 165.0262\n",
      "Epoch 55/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 24.1118 - mse: 24.1118 - val_loss: 155.0342 - val_mse: 155.0342\n",
      "Epoch 56/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 21.4725 - mse: 21.4725 - val_loss: 165.3629 - val_mse: 165.3629\n",
      "Epoch 57/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 17.0342 - mse: 17.0342 - val_loss: 151.3899 - val_mse: 151.3899\n",
      "Epoch 58/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 15.4632 - mse: 15.4632 - val_loss: 156.9897 - val_mse: 156.9897\n",
      "Epoch 59/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 13.4561 - mse: 13.4561 - val_loss: 155.3731 - val_mse: 155.3731\n",
      "Epoch 60/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.9793 - mse: 12.9793 - val_loss: 159.8267 - val_mse: 159.8267\n",
      "Epoch 61/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 16.4244 - mse: 16.4244 - val_loss: 156.2958 - val_mse: 156.2958\n",
      "Epoch 62/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 18.6686 - mse: 18.6686 - val_loss: 163.9067 - val_mse: 163.9067\n",
      "Epoch 63/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 14.8808 - mse: 14.8808 - val_loss: 153.4376 - val_mse: 153.4376\n",
      "Epoch 64/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 10.4855 - mse: 10.4855 - val_loss: 155.1161 - val_mse: 155.1161\n",
      "Epoch 65/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 10.1441 - mse: 10.1441 - val_loss: 152.7152 - val_mse: 152.7152\n",
      "Epoch 66/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 9.1525 - mse: 9.1525 - val_loss: 155.1341 - val_mse: 155.1341\n",
      "Epoch 67/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 9.9190 - mse: 9.9190 - val_loss: 150.9742 - val_mse: 150.9742\n",
      "Epoch 68/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 10.3325 - mse: 10.3325 - val_loss: 153.1410 - val_mse: 153.1410\n",
      "Epoch 69/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 8.7205 - mse: 8.7205 - val_loss: 150.8539 - val_mse: 150.8539\n",
      "Epoch 70/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 7.6941 - mse: 7.6941 - val_loss: 152.1244 - val_mse: 152.1244\n",
      "Epoch 71/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 10.0632 - mse: 10.0632 - val_loss: 149.7484 - val_mse: 149.7484\n",
      "Epoch 72/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 9.0762 - mse: 9.0762 - val_loss: 155.8945 - val_mse: 155.8945\n",
      "Epoch 73/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 9.0808 - mse: 9.0808 - val_loss: 150.7389 - val_mse: 150.7389\n",
      "Epoch 74/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 8.0680 - mse: 8.0680 - val_loss: 148.7560 - val_mse: 148.7560\n",
      "Epoch 75/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 8.4263 - mse: 8.4263 - val_loss: 149.9965 - val_mse: 149.9965\n",
      "Epoch 76/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 7.4882 - mse: 7.4882 - val_loss: 148.6008 - val_mse: 148.6008\n",
      "Epoch 77/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 6.1432 - mse: 6.1432 - val_loss: 149.6287 - val_mse: 149.6287\n",
      "Epoch 78/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 6.1819 - mse: 6.1819 - val_loss: 145.5000 - val_mse: 145.5000\n",
      "Epoch 79/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.8761 - mse: 7.8761 - val_loss: 148.4901 - val_mse: 148.4901\n",
      "Epoch 80/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 8.4683 - mse: 8.4683 - val_loss: 147.1540 - val_mse: 147.1540\n",
      "Epoch 81/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 9.7841 - mse: 9.7841 - val_loss: 149.8892 - val_mse: 149.8892\n",
      "Epoch 82/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 5.8451 - mse: 5.8451 - val_loss: 146.0318 - val_mse: 146.0318\n",
      "Epoch 83/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 5.7668 - mse: 5.7668 - val_loss: 147.7126 - val_mse: 147.7126\n",
      "Epoch 84/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 7.5148 - mse: 7.5148 - val_loss: 145.3078 - val_mse: 145.3078\n",
      "Epoch 85/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 10.4079 - mse: 10.4079 - val_loss: 148.6507 - val_mse: 148.6507\n",
      "Epoch 86/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 9.1198 - mse: 9.1198 - val_loss: 148.7706 - val_mse: 148.7706\n",
      "Epoch 87/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 10.3088 - mse: 10.3088 - val_loss: 147.1218 - val_mse: 147.1218\n",
      "Epoch 88/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 7.3896 - mse: 7.3896 - val_loss: 149.1261 - val_mse: 149.1261\n",
      "Epoch 89/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 7.7050 - mse: 7.7050 - val_loss: 144.7238 - val_mse: 144.7238\n",
      "Epoch 90/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 6.6971 - mse: 6.6971 - val_loss: 147.1788 - val_mse: 147.1788\n",
      "Epoch 91/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 6.5244 - mse: 6.5244 - val_loss: 143.7971 - val_mse: 143.7971\n",
      "Epoch 92/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 6.6168 - mse: 6.6168 - val_loss: 142.2868 - val_mse: 142.2868\n",
      "Epoch 93/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 6.3467 - mse: 6.3467 - val_loss: 146.3560 - val_mse: 146.3560\n",
      "Epoch 94/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 7.2443 - mse: 7.2443 - val_loss: 145.4987 - val_mse: 145.4987\n",
      "Epoch 95/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 8.4994 - mse: 8.4994 - val_loss: 147.2331 - val_mse: 147.2331\n",
      "Epoch 96/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 7.6728 - mse: 7.6728 - val_loss: 142.3077 - val_mse: 142.3077\n",
      "Epoch 97/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 6.4119 - mse: 6.4119 - val_loss: 149.0724 - val_mse: 149.0724\n",
      "Epoch 98/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.9218 - mse: 4.9218 - val_loss: 141.3774 - val_mse: 141.3774\n",
      "Epoch 99/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.2951 - mse: 4.2951 - val_loss: 146.8945 - val_mse: 146.8945\n",
      "Epoch 100/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3.1520 - mse: 3.1520 - val_loss: 141.3835 - val_mse: 141.3835\n",
      "Epoch 101/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 5.6999 - mse: 5.6999 - val_loss: 147.4486 - val_mse: 147.4486\n",
      "Epoch 102/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3.6059 - mse: 3.6059 - val_loss: 140.6186 - val_mse: 140.6186\n",
      "Epoch 103/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2.9495 - mse: 2.9495 - val_loss: 144.3919 - val_mse: 144.3919\n",
      "Epoch 104/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3.5326 - mse: 3.5326 - val_loss: 141.7537 - val_mse: 141.7537\n",
      "Epoch 105/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3.3791 - mse: 3.3791 - val_loss: 144.5489 - val_mse: 144.5489\n",
      "Epoch 106/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4.1283 - mse: 4.1283 - val_loss: 142.9508 - val_mse: 142.9508\n",
      "Epoch 107/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4.9774 - mse: 4.9774 - val_loss: 142.5531 - val_mse: 142.5531\n",
      "Epoch 108/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 5.9432 - mse: 5.9432 - val_loss: 144.1718 - val_mse: 144.1718\n",
      "Epoch 109/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 8.1146 - mse: 8.1146 - val_loss: 142.7286 - val_mse: 142.7286\n",
      "Epoch 110/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 10.4414 - mse: 10.4414 - val_loss: 152.8608 - val_mse: 152.8608\n",
      "Epoch 111/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 8.7257 - mse: 8.7257 - val_loss: 145.9419 - val_mse: 145.9419\n",
      "Epoch 112/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 6.1445 - mse: 6.1445 - val_loss: 140.4686 - val_mse: 140.4686\n",
      "Epoch 113/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 8.0523 - mse: 8.0523 - val_loss: 144.1522 - val_mse: 144.1522\n",
      "Epoch 114/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 7.4997 - mse: 7.4997 - val_loss: 147.8684 - val_mse: 147.8684\n",
      "Epoch 115/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 5.9067 - mse: 5.9067 - val_loss: 146.8813 - val_mse: 146.8813\n",
      "Epoch 116/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 6.5676 - mse: 6.5676 - val_loss: 140.9052 - val_mse: 140.9052\n",
      "Epoch 117/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4.4203 - mse: 4.4203 - val_loss: 141.0134 - val_mse: 141.0134\n",
      "Epoch 118/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3.2295 - mse: 3.2295 - val_loss: 143.1540 - val_mse: 143.1540\n",
      "Epoch 119/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2.7543 - mse: 2.7543 - val_loss: 143.0308 - val_mse: 143.0308\n",
      "Epoch 120/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2.7452 - mse: 2.7452 - val_loss: 140.0875 - val_mse: 140.0875\n",
      "Epoch 121/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2.7633 - mse: 2.7633 - val_loss: 142.5469 - val_mse: 142.5469\n",
      "Epoch 122/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2.9185 - mse: 2.9185 - val_loss: 140.1526 - val_mse: 140.1526\n",
      "Epoch 123/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3.6960 - mse: 3.6960 - val_loss: 144.1141 - val_mse: 144.1141\n",
      "Epoch 124/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4.4744 - mse: 4.4744 - val_loss: 141.8598 - val_mse: 141.8598\n",
      "Epoch 125/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3.3585 - mse: 3.3585 - val_loss: 147.3109 - val_mse: 147.3109\n",
      "Epoch 126/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3.7018 - mse: 3.7018 - val_loss: 141.5334 - val_mse: 141.5334\n",
      "Epoch 127/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3.0080 - mse: 3.0080 - val_loss: 140.9877 - val_mse: 140.9877\n",
      "Epoch 128/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.3446 - mse: 2.3446 - val_loss: 139.0275 - val_mse: 139.0275\n",
      "Epoch 129/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2.1489 - mse: 2.1489 - val_loss: 145.3197 - val_mse: 145.3197\n",
      "Epoch 130/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2.4417 - mse: 2.4417 - val_loss: 143.7337 - val_mse: 143.7337\n",
      "Epoch 131/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4.6896 - mse: 4.6896 - val_loss: 141.3323 - val_mse: 141.3323\n",
      "Epoch 132/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3.5281 - mse: 3.5281 - val_loss: 141.8355 - val_mse: 141.8355\n",
      "Epoch 133/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2.8403 - mse: 2.8403 - val_loss: 140.5718 - val_mse: 140.5718\n",
      "Epoch 134/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2.4017 - mse: 2.4017 - val_loss: 144.9307 - val_mse: 144.9307\n",
      "Epoch 135/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3.2926 - mse: 3.2926 - val_loss: 136.0722 - val_mse: 136.0722\n",
      "Epoch 136/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 5.2843 - mse: 5.2843 - val_loss: 144.9373 - val_mse: 144.9373\n",
      "Epoch 137/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 10.1095 - mse: 10.1095 - val_loss: 147.1322 - val_mse: 147.1322\n",
      "Epoch 138/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 16.4273 - mse: 16.4273 - val_loss: 148.3491 - val_mse: 148.3491\n",
      "Epoch 139/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 17.4847 - mse: 17.4847 - val_loss: 141.1936 - val_mse: 141.1936\n",
      "Epoch 140/300\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 13.2147 - mse: 13.2147 - val_loss: 148.6381 - val_mse: 148.6381\n",
      "Epoch 141/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 15.0826 - mse: 15.0826 - val_loss: 141.5991 - val_mse: 141.5991\n",
      "Epoch 142/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 13.3338 - mse: 13.3338 - val_loss: 156.4189 - val_mse: 156.4189\n",
      "Epoch 143/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 8.8666 - mse: 8.8666 - val_loss: 149.7003 - val_mse: 149.7003\n",
      "Epoch 144/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 9.1145 - mse: 9.1145 - val_loss: 151.0259 - val_mse: 151.0259\n",
      "Epoch 145/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 10.5104 - mse: 10.5104 - val_loss: 148.4170 - val_mse: 148.4170\n",
      "Epoch 146/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 8.2089 - mse: 8.2089 - val_loss: 148.6541 - val_mse: 148.6541\n",
      "Epoch 147/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 5.9506 - mse: 5.9506 - val_loss: 140.9194 - val_mse: 140.9194\n",
      "Epoch 148/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3.0095 - mse: 3.0095 - val_loss: 159.1534 - val_mse: 159.1534\n",
      "Epoch 149/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3.6063 - mse: 3.6063 - val_loss: 141.7055 - val_mse: 141.7055\n",
      "Epoch 150/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3.7946 - mse: 3.7946 - val_loss: 138.5267 - val_mse: 138.5267\n",
      "Epoch 151/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2.6881 - mse: 2.6881 - val_loss: 146.0923 - val_mse: 146.0923\n",
      "Epoch 152/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2.5069 - mse: 2.5069 - val_loss: 143.8346 - val_mse: 143.8346\n",
      "Epoch 153/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2.4439 - mse: 2.4439 - val_loss: 143.2155 - val_mse: 143.2155\n",
      "Epoch 154/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.4617 - mse: 1.4617 - val_loss: 140.0405 - val_mse: 140.0405\n",
      "Epoch 155/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.1993 - mse: 1.1993 - val_loss: 142.5621 - val_mse: 142.5621\n",
      "Epoch 156/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.1898 - mse: 1.1898 - val_loss: 141.8266 - val_mse: 141.8266\n",
      "Epoch 157/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.6001 - mse: 1.6001 - val_loss: 145.0404 - val_mse: 145.0404\n",
      "Epoch 158/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3.4493 - mse: 3.4493 - val_loss: 138.0398 - val_mse: 138.0398\n",
      "Epoch 159/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3.1476 - mse: 3.1476 - val_loss: 146.5665 - val_mse: 146.5665\n",
      "Epoch 160/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2.7969 - mse: 2.7969 - val_loss: 142.0430 - val_mse: 142.0430\n",
      "Epoch 161/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2.0206 - mse: 2.0206 - val_loss: 141.9381 - val_mse: 141.9381\n",
      "Epoch 162/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 9.8714 - mse: 9.8714 - val_loss: 146.5578 - val_mse: 146.5578\n",
      "Epoch 163/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 8.0232 - mse: 8.0232 - val_loss: 149.3183 - val_mse: 149.3183\n",
      "Epoch 164/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 15.6181 - mse: 15.6181 - val_loss: 158.8181 - val_mse: 158.8181\n",
      "Epoch 165/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 12.7291 - mse: 12.7291 - val_loss: 153.9935 - val_mse: 153.9935\n",
      "Epoch 166/300\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 16.7598 - mse: 16.7598 - val_loss: 147.5866 - val_mse: 147.5866\n",
      "Epoch 167/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 8.9160 - mse: 8.9160 - val_loss: 139.8586 - val_mse: 139.8586\n",
      "Epoch 168/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 10.5726 - mse: 10.5726 - val_loss: 145.9434 - val_mse: 145.9434\n",
      "Epoch 169/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 31.5755 - mse: 31.5755 - val_loss: 152.3368 - val_mse: 152.3368\n",
      "Epoch 170/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 40.9012 - mse: 40.9012 - val_loss: 157.0141 - val_mse: 157.0141\n",
      "Epoch 171/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 13.6150 - mse: 13.6150 - val_loss: 142.8405 - val_mse: 142.8405\n",
      "Epoch 172/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 5.5519 - mse: 5.5519 - val_loss: 143.8977 - val_mse: 143.8977\n",
      "Epoch 173/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3.7024 - mse: 3.7024 - val_loss: 140.4538 - val_mse: 140.4538\n",
      "Epoch 174/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2.4695 - mse: 2.4695 - val_loss: 139.7076 - val_mse: 139.7076\n",
      "Epoch 175/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2.1375 - mse: 2.1375 - val_loss: 143.3700 - val_mse: 143.3700\n",
      "Epoch 176/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.2255 - mse: 2.2255 - val_loss: 138.6016 - val_mse: 138.6016\n",
      "Epoch 177/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3.5584 - mse: 3.5584 - val_loss: 143.1340 - val_mse: 143.1340\n",
      "Epoch 178/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 5.0036 - mse: 5.0036 - val_loss: 136.5911 - val_mse: 136.5911\n",
      "Epoch 179/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3.7726 - mse: 3.7726 - val_loss: 150.0998 - val_mse: 150.0998\n",
      "Epoch 180/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3.5105 - mse: 3.5105 - val_loss: 137.6414 - val_mse: 137.6414\n",
      "Epoch 181/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3.3629 - mse: 3.3629 - val_loss: 141.9968 - val_mse: 141.9968\n",
      "Epoch 182/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2.6103 - mse: 2.6103 - val_loss: 137.3124 - val_mse: 137.3124\n",
      "Epoch 183/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3.5057 - mse: 3.5057 - val_loss: 147.5298 - val_mse: 147.5298\n",
      "Epoch 184/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 7.9062 - mse: 7.9062 - val_loss: 141.2580 - val_mse: 141.2580\n",
      "Epoch 185/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 5.8364 - mse: 5.8364 - val_loss: 149.4986 - val_mse: 149.4986\n",
      "Epoch 186/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.0684 - mse: 8.0684 - val_loss: 136.4226 - val_mse: 136.4226\n",
      "Epoch 187/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 10.4857 - mse: 10.4857 - val_loss: 143.7670 - val_mse: 143.7670\n",
      "Epoch 188/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 11.2356 - mse: 11.2356 - val_loss: 140.3026 - val_mse: 140.3026\n",
      "Epoch 189/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 8.4473 - mse: 8.4473 - val_loss: 137.8276 - val_mse: 137.8276\n",
      "Epoch 190/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 24.8373 - mse: 24.8373 - val_loss: 150.8512 - val_mse: 150.8512\n",
      "Epoch 191/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 12.9691 - mse: 12.9691 - val_loss: 146.3169 - val_mse: 146.3169\n",
      "Epoch 192/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 18.8288 - mse: 18.8288 - val_loss: 150.0997 - val_mse: 150.0997\n",
      "Epoch 193/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 9.0060 - mse: 9.0060 - val_loss: 147.4158 - val_mse: 147.4158\n",
      "Epoch 194/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4.1772 - mse: 4.1772 - val_loss: 144.8184 - val_mse: 144.8184\n",
      "Epoch 195/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3.4561 - mse: 3.4561 - val_loss: 142.3317 - val_mse: 142.3317\n",
      "Epoch 196/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.4366 - mse: 2.4366 - val_loss: 144.4296 - val_mse: 144.4296\n",
      "Epoch 197/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2.8300 - mse: 2.8300 - val_loss: 140.4072 - val_mse: 140.4072\n",
      "Epoch 198/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2.2548 - mse: 2.2548 - val_loss: 145.6351 - val_mse: 145.6351\n",
      "Epoch 199/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2.0291 - mse: 2.0291 - val_loss: 138.6639 - val_mse: 138.6639\n",
      "Epoch 200/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.2320 - mse: 1.2320 - val_loss: 141.4721 - val_mse: 141.4721\n",
      "Epoch 201/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.0863 - mse: 1.0863 - val_loss: 139.1618 - val_mse: 139.1618\n",
      "Epoch 202/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.5091 - mse: 1.5091 - val_loss: 138.3713 - val_mse: 138.3713\n",
      "Epoch 203/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3.7663 - mse: 3.7663 - val_loss: 136.4762 - val_mse: 136.4762\n",
      "Epoch 204/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3.9101 - mse: 3.9101 - val_loss: 144.8930 - val_mse: 144.8930\n",
      "Epoch 205/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2.0450 - mse: 2.0450 - val_loss: 138.6918 - val_mse: 138.6918\n",
      "Epoch 206/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.5455 - mse: 1.5455 - val_loss: 138.9716 - val_mse: 138.9716\n",
      "Epoch 207/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.6399 - mse: 1.6399 - val_loss: 141.3805 - val_mse: 141.3805\n",
      "Epoch 208/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.3833 - mse: 1.3833 - val_loss: 138.9142 - val_mse: 138.9142\n",
      "Epoch 209/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.7561 - mse: 1.7561 - val_loss: 139.1557 - val_mse: 139.1557\n",
      "Epoch 210/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.6027 - mse: 1.6027 - val_loss: 139.2036 - val_mse: 139.2036\n",
      "Epoch 211/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.4438 - mse: 1.4438 - val_loss: 141.0347 - val_mse: 141.0347\n",
      "Epoch 212/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.1885 - mse: 1.1885 - val_loss: 136.8781 - val_mse: 136.8781\n",
      "Epoch 213/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.2775 - mse: 1.2775 - val_loss: 143.9863 - val_mse: 143.9863\n",
      "Epoch 214/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.3064 - mse: 1.3064 - val_loss: 138.6997 - val_mse: 138.6997\n",
      "Epoch 215/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.3041 - mse: 1.3041 - val_loss: 137.5866 - val_mse: 137.5866\n",
      "Epoch 216/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2.1627 - mse: 2.1627 - val_loss: 143.4776 - val_mse: 143.4776\n",
      "Epoch 217/300\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2.7128 - mse: 2.7128 - val_loss: 143.3198 - val_mse: 143.3198\n",
      "Epoch 218/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3.6452 - mse: 3.6452 - val_loss: 143.1346 - val_mse: 143.1346\n",
      "Epoch 219/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 5.2967 - mse: 5.2967 - val_loss: 146.1908 - val_mse: 146.1908\n",
      "Epoch 220/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4.5427 - mse: 4.5427 - val_loss: 143.2739 - val_mse: 143.2739\n",
      "Epoch 221/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 6.5175 - mse: 6.5175 - val_loss: 136.7361 - val_mse: 136.7361\n",
      "Epoch 222/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.2705 - mse: 7.2705 - val_loss: 145.7267 - val_mse: 145.7267\n",
      "Epoch 223/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.7268 - mse: 5.7268 - val_loss: 143.9312 - val_mse: 143.9312\n",
      "Epoch 224/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 5.1091 - mse: 5.1091 - val_loss: 148.8173 - val_mse: 148.8173\n",
      "Epoch 225/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3.6349 - mse: 3.6349 - val_loss: 136.4189 - val_mse: 136.4189\n",
      "Epoch 226/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3.1560 - mse: 3.1560 - val_loss: 147.3410 - val_mse: 147.3410\n",
      "Epoch 227/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3.8240 - mse: 3.8240 - val_loss: 140.9135 - val_mse: 140.9135\n",
      "Epoch 228/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3.6294 - mse: 3.6294 - val_loss: 143.6654 - val_mse: 143.6654\n",
      "Epoch 229/300\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3.7162 - mse: 3.7162 - val_loss: 137.3853 - val_mse: 137.3853\n",
      "Epoch 230/300\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 4.4564 - mse: 4.4564 - val_loss: 140.9479 - val_mse: 140.9479\n",
      "Epoch 231/300\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 4.2768 - mse: 4.2768 - val_loss: 142.0037 - val_mse: 142.0037\n",
      "Epoch 232/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3.6771 - mse: 3.6771 - val_loss: 138.2580 - val_mse: 138.2580\n",
      "Epoch 233/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2.9138 - mse: 2.9138 - val_loss: 144.4129 - val_mse: 144.4129\n",
      "Epoch 234/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3.1343 - mse: 3.1343 - val_loss: 139.0777 - val_mse: 139.0777\n",
      "Epoch 235/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3.0810 - mse: 3.0810 - val_loss: 140.4012 - val_mse: 140.4012\n",
      "Epoch 236/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2.8352 - mse: 2.8352 - val_loss: 140.1657 - val_mse: 140.1657\n",
      "Epoch 237/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2.3450 - mse: 2.3450 - val_loss: 139.5522 - val_mse: 139.5522\n",
      "Epoch 238/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3.2786 - mse: 3.2786 - val_loss: 142.3672 - val_mse: 142.3672\n",
      "Epoch 239/300\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3.7918 - mse: 3.7918 - val_loss: 136.4848 - val_mse: 136.4848\n",
      "Epoch 240/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.9229 - mse: 3.9229 - val_loss: 141.7071 - val_mse: 141.7071\n",
      "Epoch 241/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 5.3958 - mse: 5.3958 - val_loss: 142.4525 - val_mse: 142.4525\n",
      "Epoch 242/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 53.2131 - mse: 53.2131 - val_loss: 149.9250 - val_mse: 149.9250\n",
      "Epoch 243/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 14.9698 - mse: 14.9698 - val_loss: 143.2487 - val_mse: 143.2487\n",
      "Epoch 244/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 12.8251 - mse: 12.8251 - val_loss: 142.9103 - val_mse: 142.9103\n",
      "Epoch 245/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 11.7622 - mse: 11.7622 - val_loss: 154.9297 - val_mse: 154.9297\n",
      "Epoch 246/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 8.2128 - mse: 8.2128 - val_loss: 149.1133 - val_mse: 149.1133\n",
      "Epoch 247/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 7.7466 - mse: 7.7466 - val_loss: 139.3609 - val_mse: 139.3609\n",
      "Epoch 248/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 6.6985 - mse: 6.6985 - val_loss: 151.3093 - val_mse: 151.3093\n",
      "Epoch 249/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 5.7814 - mse: 5.7814 - val_loss: 138.8767 - val_mse: 138.8767\n",
      "Epoch 250/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3.5837 - mse: 3.5837 - val_loss: 144.0372 - val_mse: 144.0372\n",
      "Epoch 251/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.8584 - mse: 1.8584 - val_loss: 139.3224 - val_mse: 139.3224\n",
      "Epoch 252/300\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1.2421 - mse: 1.2421 - val_loss: 140.1148 - val_mse: 140.1148\n",
      "Epoch 253/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.1316 - mse: 2.1316 - val_loss: 141.3665 - val_mse: 141.3665\n",
      "Epoch 254/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.0959 - mse: 2.0959 - val_loss: 142.4960 - val_mse: 142.4960\n",
      "Epoch 255/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2.4509 - mse: 2.4509 - val_loss: 147.1523 - val_mse: 147.1523\n",
      "Epoch 256/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.7109 - mse: 1.7109 - val_loss: 140.8531 - val_mse: 140.8531\n",
      "Epoch 257/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.8170 - mse: 1.8170 - val_loss: 143.6731 - val_mse: 143.6731\n",
      "Epoch 258/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.3420 - mse: 1.3420 - val_loss: 139.4522 - val_mse: 139.4522\n",
      "Epoch 259/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.1093 - mse: 1.1093 - val_loss: 144.2940 - val_mse: 144.2940\n",
      "Epoch 260/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.9448 - mse: 0.9448 - val_loss: 140.2416 - val_mse: 140.2416\n",
      "Epoch 261/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.8695 - mse: 0.8695 - val_loss: 142.4241 - val_mse: 142.4241\n",
      "Epoch 262/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.7265 - mse: 0.7265 - val_loss: 139.7244 - val_mse: 139.7244\n",
      "Epoch 263/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.6584 - mse: 0.6584 - val_loss: 143.8490 - val_mse: 143.8490\n",
      "Epoch 264/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.0126 - mse: 1.0126 - val_loss: 140.2110 - val_mse: 140.2110\n",
      "Epoch 265/300\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1.4082 - mse: 1.4082 - val_loss: 143.5448 - val_mse: 143.5448\n",
      "Epoch 266/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.5743 - mse: 2.5743 - val_loss: 141.0943 - val_mse: 141.0943\n",
      "Epoch 267/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3.3220 - mse: 3.3220 - val_loss: 145.6597 - val_mse: 145.6597\n",
      "Epoch 268/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.0525 - mse: 4.0525 - val_loss: 141.9766 - val_mse: 141.9766\n",
      "Epoch 269/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4.6939 - mse: 4.6939 - val_loss: 144.2103 - val_mse: 144.2103\n",
      "Epoch 270/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4.6251 - mse: 4.6251 - val_loss: 146.8945 - val_mse: 146.8945\n",
      "Epoch 271/300\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 5.9765 - mse: 5.9765 - val_loss: 146.2864 - val_mse: 146.2864\n",
      "Epoch 272/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 7.3455 - mse: 7.3455 - val_loss: 165.6006 - val_mse: 165.6006\n",
      "Epoch 273/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 7.7839 - mse: 7.7839 - val_loss: 140.6214 - val_mse: 140.6214\n",
      "Epoch 274/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.9276 - mse: 8.9276 - val_loss: 154.9134 - val_mse: 154.9134\n",
      "Epoch 275/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.8614 - mse: 5.8614 - val_loss: 143.7445 - val_mse: 143.7445\n",
      "Epoch 276/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.2395 - mse: 4.2395 - val_loss: 144.1991 - val_mse: 144.1991\n",
      "Epoch 277/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4.1018 - mse: 4.1018 - val_loss: 141.7186 - val_mse: 141.7186\n",
      "Epoch 278/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4.2750 - mse: 4.2750 - val_loss: 142.8616 - val_mse: 142.8616\n",
      "Epoch 279/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4.0288 - mse: 4.0288 - val_loss: 142.6432 - val_mse: 142.6432\n",
      "Epoch 280/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4.7684 - mse: 4.7684 - val_loss: 150.0504 - val_mse: 150.0504\n",
      "Epoch 281/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3.8168 - mse: 3.8168 - val_loss: 135.1864 - val_mse: 135.1864\n",
      "Epoch 282/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4.6362 - mse: 4.6362 - val_loss: 146.8570 - val_mse: 146.8570\n",
      "Epoch 283/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 6.7766 - mse: 6.7766 - val_loss: 142.4147 - val_mse: 142.4147\n",
      "Epoch 284/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4.3323 - mse: 4.3323 - val_loss: 141.3163 - val_mse: 141.3163\n",
      "Epoch 285/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4.4363 - mse: 4.4363 - val_loss: 141.1463 - val_mse: 141.1463\n",
      "Epoch 286/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3.0259 - mse: 3.0259 - val_loss: 141.2491 - val_mse: 141.2491\n",
      "Epoch 287/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.8055 - mse: 1.8055 - val_loss: 139.8736 - val_mse: 139.8736\n",
      "Epoch 288/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.9865 - mse: 1.9865 - val_loss: 142.0486 - val_mse: 142.0486\n",
      "Epoch 289/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.7260 - mse: 1.7260 - val_loss: 142.4035 - val_mse: 142.4035\n",
      "Epoch 290/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.1407 - mse: 1.1407 - val_loss: 142.9672 - val_mse: 142.9672\n",
      "Epoch 291/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.0343 - mse: 1.0343 - val_loss: 141.5115 - val_mse: 141.5115\n",
      "Epoch 292/300\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1.1869 - mse: 1.1869 - val_loss: 140.6502 - val_mse: 140.6502\n",
      "Epoch 293/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.1263 - mse: 1.1263 - val_loss: 141.9587 - val_mse: 141.9587\n",
      "Epoch 294/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.1979 - mse: 1.1979 - val_loss: 140.2795 - val_mse: 140.2795\n",
      "Epoch 295/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.9838 - mse: 0.9838 - val_loss: 143.1154 - val_mse: 143.1154\n",
      "Epoch 296/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.9465 - mse: 0.9465 - val_loss: 141.8839 - val_mse: 141.8839\n",
      "Epoch 297/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.9769 - mse: 0.9769 - val_loss: 143.4047 - val_mse: 143.4047\n",
      "Epoch 298/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.1058 - mse: 1.1058 - val_loss: 141.5547 - val_mse: 141.5547\n",
      "Epoch 299/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.2321 - mse: 1.2321 - val_loss: 145.2162 - val_mse: 145.2162\n",
      "Epoch 300/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 1.2986 - mse: 1.2986 - val_loss: 140.9947 - val_mse: 140.9947\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x191acf08cd0>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.fit(x_train, y_train, batch_size=16, epochs=300, validation_data=(x_test2,y_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_2.predict(x_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rezultati = pd.DataFrame({'pred':predictions.reshape(-1,), 'test':y_test2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           pred   test\n",
      "33   136.324356  135.0\n",
      "236   99.960251  100.3\n",
      "492   67.274597  160.0\n",
      "48   122.998703  120.0\n",
      "90   112.874168  110.0\n",
      "..          ...    ...\n",
      "290  121.819878  158.0\n",
      "134  218.427261  219.0\n",
      "87   109.440247  110.0\n",
      "15   121.079590  120.0\n",
      "130  100.188232  100.0\n",
      "\n",
      "[125 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_rezultati)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rezultati['diff'] = df_rezultati['test'] - df_rezultati['pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006215295410156273\n",
      "11.921901953199201\n"
     ]
    }
   ],
   "source": [
    "print(df_rezultati['diff'].mean())\n",
    "print(df_rezultati['diff'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2.,  1.,  4.,  9., 99.,  4.,  2.,  2.,  1.,  0.,  0.,  0.,  0.,\n",
       "         0.,  1.]),\n",
       " array([-38.64624786, -29.88813782, -21.13002777, -12.37191772,\n",
       "         -3.61380768,   5.14430237,  13.90241241,  22.66052246,\n",
       "         31.41863251,  40.17674255,  48.9348526 ,  57.69296265,\n",
       "         66.45107269,  75.20918274,  83.96729279,  92.72540283]),\n",
       " <BarContainer object of 15 artists>)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df_rezultati[\"diff\"], bins=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.81691792324773\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rmse = mean_squared_error(predictions,y_test2,squared=False)\n",
    "print(rmse/y_test2.mean()*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>id_property</th>\n",
       "      <th>beds_basic</th>\n",
       "      <th>amount</th>\n",
       "      <th>area</th>\n",
       "      <th>floor</th>\n",
       "      <th>category</th>\n",
       "      <th>city</th>\n",
       "      <th>beds_additional</th>\n",
       "      <th>garden</th>\n",
       "      <th>...</th>\n",
       "      <th>hot_water_supply</th>\n",
       "      <th>no_smoking_rooms</th>\n",
       "      <th>in_mini_soccer</th>\n",
       "      <th>special_business</th>\n",
       "      <th>special_groups</th>\n",
       "      <th>unit_bedroom_mosquito_net</th>\n",
       "      <th>mosquito_net</th>\n",
       "      <th>property_internet_location</th>\n",
       "      <th>location_turistcomplex</th>\n",
       "      <th>in_food_local_speciality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24598</td>\n",
       "      <td>10049</td>\n",
       "      <td>2</td>\n",
       "      <td>125.0</td>\n",
       "      <td>-0.524784</td>\n",
       "      <td>3.043402</td>\n",
       "      <td>1.736446</td>\n",
       "      <td>-0.448308</td>\n",
       "      <td>1.114105</td>\n",
       "      <td>-0.816996</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.04695</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.121988</td>\n",
       "      <td>-0.054233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24607</td>\n",
       "      <td>10055</td>\n",
       "      <td>2</td>\n",
       "      <td>79.1</td>\n",
       "      <td>0.050333</td>\n",
       "      <td>-0.623736</td>\n",
       "      <td>-0.159881</td>\n",
       "      <td>1.431988</td>\n",
       "      <td>1.114105</td>\n",
       "      <td>-0.816996</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.04695</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.121988</td>\n",
       "      <td>-0.054233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24608</td>\n",
       "      <td>10056</td>\n",
       "      <td>2</td>\n",
       "      <td>70.0</td>\n",
       "      <td>-0.524784</td>\n",
       "      <td>1.821022</td>\n",
       "      <td>-0.159881</td>\n",
       "      <td>-0.250382</td>\n",
       "      <td>1.114105</td>\n",
       "      <td>1.223997</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.04695</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.121988</td>\n",
       "      <td>-0.054233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24609</td>\n",
       "      <td>10056</td>\n",
       "      <td>2</td>\n",
       "      <td>59.0</td>\n",
       "      <td>-0.812343</td>\n",
       "      <td>1.821022</td>\n",
       "      <td>-0.159881</td>\n",
       "      <td>-0.250382</td>\n",
       "      <td>-1.105967</td>\n",
       "      <td>1.223997</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.04695</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.121988</td>\n",
       "      <td>-0.054233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24610</td>\n",
       "      <td>10056</td>\n",
       "      <td>2</td>\n",
       "      <td>70.0</td>\n",
       "      <td>-0.524784</td>\n",
       "      <td>3.043402</td>\n",
       "      <td>-0.159881</td>\n",
       "      <td>-0.250382</td>\n",
       "      <td>1.114105</td>\n",
       "      <td>1.223997</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.04695</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.121988</td>\n",
       "      <td>-0.054233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>24508</td>\n",
       "      <td>10011</td>\n",
       "      <td>2</td>\n",
       "      <td>57.0</td>\n",
       "      <td>-0.381005</td>\n",
       "      <td>1.821022</td>\n",
       "      <td>-0.159881</td>\n",
       "      <td>1.135099</td>\n",
       "      <td>0.004069</td>\n",
       "      <td>1.223997</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.04695</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.121988</td>\n",
       "      <td>-0.054233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>24514</td>\n",
       "      <td>10014</td>\n",
       "      <td>2</td>\n",
       "      <td>65.0</td>\n",
       "      <td>-0.841099</td>\n",
       "      <td>0.598643</td>\n",
       "      <td>-0.159881</td>\n",
       "      <td>1.431988</td>\n",
       "      <td>0.004069</td>\n",
       "      <td>-0.816996</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.04695</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.121988</td>\n",
       "      <td>-0.054233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>24515</td>\n",
       "      <td>10014</td>\n",
       "      <td>2</td>\n",
       "      <td>60.0</td>\n",
       "      <td>-1.042390</td>\n",
       "      <td>0.598643</td>\n",
       "      <td>-0.159881</td>\n",
       "      <td>1.431988</td>\n",
       "      <td>-1.105967</td>\n",
       "      <td>-0.816996</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.04695</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.121988</td>\n",
       "      <td>-0.054233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>24526</td>\n",
       "      <td>10019</td>\n",
       "      <td>2</td>\n",
       "      <td>90.0</td>\n",
       "      <td>-0.237225</td>\n",
       "      <td>-0.623736</td>\n",
       "      <td>-0.159881</td>\n",
       "      <td>-0.448308</td>\n",
       "      <td>1.114105</td>\n",
       "      <td>-0.816996</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.04695</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.121988</td>\n",
       "      <td>-0.054233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>8176</td>\n",
       "      <td>3564</td>\n",
       "      <td>2</td>\n",
       "      <td>37.0</td>\n",
       "      <td>-1.042390</td>\n",
       "      <td>1.821022</td>\n",
       "      <td>-2.056208</td>\n",
       "      <td>-0.448308</td>\n",
       "      <td>-1.105967</td>\n",
       "      <td>-0.816996</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.03832</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.054233</td>\n",
       "      <td>-0.04695</td>\n",
       "      <td>-0.027086</td>\n",
       "      <td>-0.121988</td>\n",
       "      <td>-0.054233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>555 rows × 251 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  id_property  beds_basic  amount      area     floor  category  \\\n",
       "0    24598        10049           2   125.0 -0.524784  3.043402  1.736446   \n",
       "1    24607        10055           2    79.1  0.050333 -0.623736 -0.159881   \n",
       "2    24608        10056           2    70.0 -0.524784  1.821022 -0.159881   \n",
       "3    24609        10056           2    59.0 -0.812343  1.821022 -0.159881   \n",
       "4    24610        10056           2    70.0 -0.524784  3.043402 -0.159881   \n",
       "..     ...          ...         ...     ...       ...       ...       ...   \n",
       "550  24508        10011           2    57.0 -0.381005  1.821022 -0.159881   \n",
       "551  24514        10014           2    65.0 -0.841099  0.598643 -0.159881   \n",
       "552  24515        10014           2    60.0 -1.042390  0.598643 -0.159881   \n",
       "553  24526        10019           2    90.0 -0.237225 -0.623736 -0.159881   \n",
       "554   8176         3564           2    37.0 -1.042390  1.821022 -2.056208   \n",
       "\n",
       "         city  beds_additional    garden  ...  hot_water_supply  \\\n",
       "0   -0.448308         1.114105 -0.816996  ...          -0.03832   \n",
       "1    1.431988         1.114105 -0.816996  ...          -0.03832   \n",
       "2   -0.250382         1.114105  1.223997  ...          -0.03832   \n",
       "3   -0.250382        -1.105967  1.223997  ...          -0.03832   \n",
       "4   -0.250382         1.114105  1.223997  ...          -0.03832   \n",
       "..        ...              ...       ...  ...               ...   \n",
       "550  1.135099         0.004069  1.223997  ...          -0.03832   \n",
       "551  1.431988         0.004069 -0.816996  ...          -0.03832   \n",
       "552  1.431988        -1.105967 -0.816996  ...          -0.03832   \n",
       "553 -0.448308         1.114105 -0.816996  ...          -0.03832   \n",
       "554 -0.448308        -1.105967 -0.816996  ...          -0.03832   \n",
       "\n",
       "     no_smoking_rooms  in_mini_soccer  special_business  special_groups  \\\n",
       "0           -0.054233       -0.027086          -0.03832       -0.027086   \n",
       "1           -0.054233       -0.027086          -0.03832       -0.027086   \n",
       "2           -0.054233       -0.027086          -0.03832       -0.027086   \n",
       "3           -0.054233       -0.027086          -0.03832       -0.027086   \n",
       "4           -0.054233       -0.027086          -0.03832       -0.027086   \n",
       "..                ...             ...               ...             ...   \n",
       "550         -0.054233       -0.027086          -0.03832       -0.027086   \n",
       "551         -0.054233       -0.027086          -0.03832       -0.027086   \n",
       "552         -0.054233       -0.027086          -0.03832       -0.027086   \n",
       "553         -0.054233       -0.027086          -0.03832       -0.027086   \n",
       "554         -0.054233       -0.027086          -0.03832       -0.027086   \n",
       "\n",
       "     unit_bedroom_mosquito_net  mosquito_net  property_internet_location  \\\n",
       "0                    -0.054233      -0.04695                   -0.027086   \n",
       "1                    -0.054233      -0.04695                   -0.027086   \n",
       "2                    -0.054233      -0.04695                   -0.027086   \n",
       "3                    -0.054233      -0.04695                   -0.027086   \n",
       "4                    -0.054233      -0.04695                   -0.027086   \n",
       "..                         ...           ...                         ...   \n",
       "550                  -0.054233      -0.04695                   -0.027086   \n",
       "551                  -0.054233      -0.04695                   -0.027086   \n",
       "552                  -0.054233      -0.04695                   -0.027086   \n",
       "553                  -0.054233      -0.04695                   -0.027086   \n",
       "554                  -0.054233      -0.04695                   -0.027086   \n",
       "\n",
       "     location_turistcomplex  in_food_local_speciality  \n",
       "0                 -0.121988                 -0.054233  \n",
       "1                 -0.121988                 -0.054233  \n",
       "2                 -0.121988                 -0.054233  \n",
       "3                 -0.121988                 -0.054233  \n",
       "4                 -0.121988                 -0.054233  \n",
       "..                      ...                       ...  \n",
       "550               -0.121988                 -0.054233  \n",
       "551               -0.121988                 -0.054233  \n",
       "552               -0.121988                 -0.054233  \n",
       "553               -0.121988                 -0.054233  \n",
       "554               -0.121988                 -0.054233  \n",
       "\n",
       "[555 rows x 251 columns]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df22=df2[(df2[\"beds_basic\"]==2)&(df2[\"amount\"]<=150)]\n",
    "df22.reset_index(inplace=True,drop=True)\n",
    "df22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2=df22.iloc[:,4:]\n",
    "Y2=df22.loc[:,\"amount\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([20., 61., 77., 97., 35., 49., 26., 15.,  7., 29.]),\n",
       " array([ 33.54 ,  45.186,  56.832,  68.478,  80.124,  91.77 , 103.416,\n",
       "        115.062, 126.708, 138.354, 150.   ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train3, x_test3, y_train3, y_test3 = train_test_split(X2, Y2)\n",
    "plt.hist(y_train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = tf.keras.models.Sequential()\n",
    "model_3.add(tf.keras.Input(shape=(247,)))\n",
    "#model_3.add(tf.keras.layers.Dense(247, activation=\"relu\"))\n",
    "#model_3.add(tf.keras.layers.Dense(128, activation=\"relu\"))\n",
    "model_3.add(tf.keras.layers.Dense(64, activation=\"relu\"))\n",
    "#model_3.add(tf.keras.layers.Dense(32, activation=\"relu\"))\n",
    "model_3.add(tf.keras.layers.Dropout(0.1))\n",
    "model_3.add(tf.keras.layers.Dense(1))\n",
    "model_3.compile(loss=\"mse\", optimizer=tf.keras.optimizers.Adam(learning_rate=0.03), metrics=[\"mse\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "26/26 [==============================] - 1s 9ms/step - loss: 2486.5745 - mse: 2486.5745 - val_loss: 622.0655 - val_mse: 622.0655\n",
      "Epoch 2/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 446.2772 - mse: 446.2772 - val_loss: 424.5453 - val_mse: 424.5453\n",
      "Epoch 3/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 212.0039 - mse: 212.0039 - val_loss: 404.2392 - val_mse: 404.2392\n",
      "Epoch 4/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 162.3643 - mse: 162.3643 - val_loss: 410.6765 - val_mse: 410.6765\n",
      "Epoch 5/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 143.5191 - mse: 143.5191 - val_loss: 401.7188 - val_mse: 401.7188\n",
      "Epoch 6/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 143.5978 - mse: 143.5978 - val_loss: 393.7800 - val_mse: 393.7800\n",
      "Epoch 7/300\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 145.3544 - mse: 145.3544 - val_loss: 415.8138 - val_mse: 415.8138\n",
      "Epoch 8/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 142.8953 - mse: 142.8953 - val_loss: 382.1642 - val_mse: 382.1642\n",
      "Epoch 9/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 132.5683 - mse: 132.5683 - val_loss: 418.3209 - val_mse: 418.3209\n",
      "Epoch 10/300\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 132.1960 - mse: 132.1960 - val_loss: 422.2743 - val_mse: 422.2743\n",
      "Epoch 11/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 113.3160 - mse: 113.3160 - val_loss: 397.2393 - val_mse: 397.2393\n",
      "Epoch 12/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 112.8637 - mse: 112.8637 - val_loss: 420.6661 - val_mse: 420.6661\n",
      "Epoch 13/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 139.6528 - mse: 139.6528 - val_loss: 431.5164 - val_mse: 431.5164\n",
      "Epoch 14/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 118.4242 - mse: 118.4242 - val_loss: 423.2742 - val_mse: 423.2742\n",
      "Epoch 15/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 127.4435 - mse: 127.4435 - val_loss: 423.9924 - val_mse: 423.9924\n",
      "Epoch 16/300\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 93.9515 - mse: 93.9515 - val_loss: 378.7431 - val_mse: 378.7431\n",
      "Epoch 17/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 102.0139 - mse: 102.0139 - val_loss: 377.8254 - val_mse: 377.8254\n",
      "Epoch 18/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 107.8393 - mse: 107.8393 - val_loss: 395.5240 - val_mse: 395.5240\n",
      "Epoch 19/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 136.6404 - mse: 136.6404 - val_loss: 378.2889 - val_mse: 378.2889\n",
      "Epoch 20/300\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 105.8382 - mse: 105.8382 - val_loss: 389.4131 - val_mse: 389.4131\n",
      "Epoch 21/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 109.2335 - mse: 109.2335 - val_loss: 406.0400 - val_mse: 406.0400\n",
      "Epoch 22/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 110.2922 - mse: 110.2922 - val_loss: 390.0987 - val_mse: 390.0987\n",
      "Epoch 23/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 114.6753 - mse: 114.6753 - val_loss: 385.3044 - val_mse: 385.3044\n",
      "Epoch 24/300\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 91.9545 - mse: 91.9545 - val_loss: 411.4063 - val_mse: 411.4063\n",
      "Epoch 25/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 160.2647 - mse: 160.2647 - val_loss: 453.7269 - val_mse: 453.7269\n",
      "Epoch 26/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 127.1045 - mse: 127.1045 - val_loss: 425.0629 - val_mse: 425.0629\n",
      "Epoch 27/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 109.3309 - mse: 109.3309 - val_loss: 463.0564 - val_mse: 463.0564\n",
      "Epoch 28/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 127.6930 - mse: 127.6930 - val_loss: 409.2233 - val_mse: 409.2233\n",
      "Epoch 29/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 110.0251 - mse: 110.0251 - val_loss: 404.1227 - val_mse: 404.1227\n",
      "Epoch 30/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 84.5999 - mse: 84.5999 - val_loss: 436.1391 - val_mse: 436.1391\n",
      "Epoch 31/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 103.7401 - mse: 103.7401 - val_loss: 378.9065 - val_mse: 378.9065\n",
      "Epoch 32/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 107.3780 - mse: 107.3780 - val_loss: 361.1341 - val_mse: 361.1341\n",
      "Epoch 33/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 86.0132 - mse: 86.0132 - val_loss: 374.1743 - val_mse: 374.1743\n",
      "Epoch 34/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 88.2762 - mse: 88.2762 - val_loss: 373.1510 - val_mse: 373.1510\n",
      "Epoch 35/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 99.7506 - mse: 99.7506 - val_loss: 368.9858 - val_mse: 368.9858\n",
      "Epoch 36/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 78.5706 - mse: 78.5706 - val_loss: 353.1020 - val_mse: 353.1020\n",
      "Epoch 37/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 99.8730 - mse: 99.8730 - val_loss: 361.3478 - val_mse: 361.3478\n",
      "Epoch 38/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 95.4654 - mse: 95.4654 - val_loss: 431.7242 - val_mse: 431.7242\n",
      "Epoch 39/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 83.5830 - mse: 83.5830 - val_loss: 366.0641 - val_mse: 366.0641\n",
      "Epoch 40/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 89.6906 - mse: 89.6906 - val_loss: 424.5351 - val_mse: 424.5351\n",
      "Epoch 41/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 99.8015 - mse: 99.8015 - val_loss: 419.9820 - val_mse: 419.9820\n",
      "Epoch 42/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 140.6008 - mse: 140.6008 - val_loss: 452.6454 - val_mse: 452.6454\n",
      "Epoch 43/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 115.6140 - mse: 115.6140 - val_loss: 399.5616 - val_mse: 399.5616\n",
      "Epoch 44/300\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 104.4843 - mse: 104.4843 - val_loss: 442.1280 - val_mse: 442.1280\n",
      "Epoch 45/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 105.1845 - mse: 105.1845 - val_loss: 406.3333 - val_mse: 406.3333\n",
      "Epoch 46/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 116.5400 - mse: 116.5400 - val_loss: 371.8781 - val_mse: 371.8781\n",
      "Epoch 47/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 95.3887 - mse: 95.3887 - val_loss: 456.8515 - val_mse: 456.8515\n",
      "Epoch 48/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 89.7469 - mse: 89.7469 - val_loss: 418.5491 - val_mse: 418.5491\n",
      "Epoch 49/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 82.6293 - mse: 82.6293 - val_loss: 368.6825 - val_mse: 368.6825\n",
      "Epoch 50/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 120.2284 - mse: 120.2284 - val_loss: 452.8388 - val_mse: 452.8388\n",
      "Epoch 51/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 136.4036 - mse: 136.4036 - val_loss: 422.3628 - val_mse: 422.3628\n",
      "Epoch 52/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 99.7489 - mse: 99.7489 - val_loss: 371.5701 - val_mse: 371.5701\n",
      "Epoch 53/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 100.7605 - mse: 100.7605 - val_loss: 381.7596 - val_mse: 381.7596\n",
      "Epoch 54/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 91.6783 - mse: 91.6783 - val_loss: 364.1869 - val_mse: 364.1869\n",
      "Epoch 55/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 101.4915 - mse: 101.4915 - val_loss: 378.7829 - val_mse: 378.7829\n",
      "Epoch 56/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 88.7762 - mse: 88.7762 - val_loss: 379.3063 - val_mse: 379.3063\n",
      "Epoch 57/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 85.7816 - mse: 85.7816 - val_loss: 410.6420 - val_mse: 410.6420\n",
      "Epoch 58/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 104.4528 - mse: 104.4528 - val_loss: 365.6147 - val_mse: 365.6147\n",
      "Epoch 59/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 123.6497 - mse: 123.6497 - val_loss: 366.6755 - val_mse: 366.6755\n",
      "Epoch 60/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 110.8965 - mse: 110.8965 - val_loss: 420.5820 - val_mse: 420.5820\n",
      "Epoch 61/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 121.6634 - mse: 121.6634 - val_loss: 357.3262 - val_mse: 357.3262\n",
      "Epoch 62/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 82.0306 - mse: 82.0306 - val_loss: 385.5058 - val_mse: 385.5058\n",
      "Epoch 63/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 83.5072 - mse: 83.5072 - val_loss: 379.3405 - val_mse: 379.3405\n",
      "Epoch 64/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 79.9937 - mse: 79.9937 - val_loss: 389.5009 - val_mse: 389.5009\n",
      "Epoch 65/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 89.2332 - mse: 89.2332 - val_loss: 385.2388 - val_mse: 385.2388\n",
      "Epoch 66/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 84.3323 - mse: 84.3323 - val_loss: 370.1375 - val_mse: 370.1375\n",
      "Epoch 67/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 86.7597 - mse: 86.7597 - val_loss: 401.9793 - val_mse: 401.9793\n",
      "Epoch 68/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 88.2226 - mse: 88.2226 - val_loss: 392.1006 - val_mse: 392.1006\n",
      "Epoch 69/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 97.7163 - mse: 97.7163 - val_loss: 370.5092 - val_mse: 370.5092\n",
      "Epoch 70/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 79.1491 - mse: 79.1491 - val_loss: 392.6204 - val_mse: 392.6204\n",
      "Epoch 71/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 104.6975 - mse: 104.6975 - val_loss: 385.6375 - val_mse: 385.6375\n",
      "Epoch 72/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 101.1745 - mse: 101.1745 - val_loss: 386.2713 - val_mse: 386.2713\n",
      "Epoch 73/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 75.2044 - mse: 75.2044 - val_loss: 392.8889 - val_mse: 392.8889\n",
      "Epoch 74/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 136.8680 - mse: 136.8680 - val_loss: 441.6580 - val_mse: 441.6580\n",
      "Epoch 75/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 124.0713 - mse: 124.0713 - val_loss: 366.2676 - val_mse: 366.2676\n",
      "Epoch 76/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 100.4459 - mse: 100.4459 - val_loss: 373.6744 - val_mse: 373.6744\n",
      "Epoch 77/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 101.5218 - mse: 101.5218 - val_loss: 411.2120 - val_mse: 411.2120\n",
      "Epoch 78/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 88.1776 - mse: 88.1776 - val_loss: 372.3141 - val_mse: 372.3141\n",
      "Epoch 79/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 92.1185 - mse: 92.1185 - val_loss: 342.8279 - val_mse: 342.8279\n",
      "Epoch 80/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 81.7460 - mse: 81.7460 - val_loss: 380.0555 - val_mse: 380.0555\n",
      "Epoch 81/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 78.5397 - mse: 78.5397 - val_loss: 374.7307 - val_mse: 374.7307\n",
      "Epoch 82/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 74.0102 - mse: 74.0102 - val_loss: 358.7682 - val_mse: 358.7682\n",
      "Epoch 83/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 74.3318 - mse: 74.3318 - val_loss: 385.8450 - val_mse: 385.8450\n",
      "Epoch 84/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 103.8848 - mse: 103.8848 - val_loss: 401.4854 - val_mse: 401.4854\n",
      "Epoch 85/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 87.3148 - mse: 87.3148 - val_loss: 416.1841 - val_mse: 416.1841\n",
      "Epoch 86/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 147.3329 - mse: 147.3329 - val_loss: 451.1173 - val_mse: 451.1173\n",
      "Epoch 87/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 88.1097 - mse: 88.1097 - val_loss: 326.0223 - val_mse: 326.0223\n",
      "Epoch 88/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 76.8975 - mse: 76.8975 - val_loss: 374.5728 - val_mse: 374.5728\n",
      "Epoch 89/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 72.3448 - mse: 72.3448 - val_loss: 357.0247 - val_mse: 357.0247\n",
      "Epoch 90/300\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 60.1714 - mse: 60.1714 - val_loss: 380.3991 - val_mse: 380.3991\n",
      "Epoch 91/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 91.7344 - mse: 91.7344 - val_loss: 361.5522 - val_mse: 361.5522\n",
      "Epoch 92/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 96.5154 - mse: 96.5154 - val_loss: 401.4925 - val_mse: 401.4925\n",
      "Epoch 93/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 103.7252 - mse: 103.7252 - val_loss: 374.7428 - val_mse: 374.7428\n",
      "Epoch 94/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 121.9786 - mse: 121.9786 - val_loss: 455.6106 - val_mse: 455.6106\n",
      "Epoch 95/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 114.0799 - mse: 114.0799 - val_loss: 378.6833 - val_mse: 378.6833\n",
      "Epoch 96/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 84.8978 - mse: 84.8978 - val_loss: 348.5633 - val_mse: 348.5633\n",
      "Epoch 97/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 65.4250 - mse: 65.4250 - val_loss: 338.2367 - val_mse: 338.2367\n",
      "Epoch 98/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 66.8519 - mse: 66.8519 - val_loss: 347.0635 - val_mse: 347.0635\n",
      "Epoch 99/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 79.7076 - mse: 79.7076 - val_loss: 341.5691 - val_mse: 341.5691\n",
      "Epoch 100/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 113.9588 - mse: 113.9588 - val_loss: 424.7334 - val_mse: 424.7334\n",
      "Epoch 101/300\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 80.4320 - mse: 80.4320 - val_loss: 350.9927 - val_mse: 350.9927\n",
      "Epoch 102/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 68.4591 - mse: 68.4591 - val_loss: 385.8872 - val_mse: 385.8872\n",
      "Epoch 103/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 133.7027 - mse: 133.7027 - val_loss: 462.9876 - val_mse: 462.9876\n",
      "Epoch 104/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 112.9927 - mse: 112.9927 - val_loss: 379.9900 - val_mse: 379.9900\n",
      "Epoch 105/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 96.6046 - mse: 96.6046 - val_loss: 368.2787 - val_mse: 368.2788\n",
      "Epoch 106/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 81.5063 - mse: 81.5063 - val_loss: 336.9473 - val_mse: 336.9473\n",
      "Epoch 107/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 78.6947 - mse: 78.6947 - val_loss: 351.0875 - val_mse: 351.0875\n",
      "Epoch 108/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 67.4158 - mse: 67.4158 - val_loss: 360.9278 - val_mse: 360.9278\n",
      "Epoch 109/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 82.8083 - mse: 82.8083 - val_loss: 422.8527 - val_mse: 422.8527\n",
      "Epoch 110/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 104.8152 - mse: 104.8152 - val_loss: 428.2639 - val_mse: 428.2639\n",
      "Epoch 111/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 96.5290 - mse: 96.5290 - val_loss: 354.0826 - val_mse: 354.0826\n",
      "Epoch 112/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 77.1210 - mse: 77.1210 - val_loss: 379.4087 - val_mse: 379.4087\n",
      "Epoch 113/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 67.5158 - mse: 67.5158 - val_loss: 352.5790 - val_mse: 352.5790\n",
      "Epoch 114/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 71.0990 - mse: 71.0990 - val_loss: 354.9991 - val_mse: 354.9991\n",
      "Epoch 115/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 72.8124 - mse: 72.8124 - val_loss: 369.2117 - val_mse: 369.2117\n",
      "Epoch 116/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 71.9652 - mse: 71.9652 - val_loss: 345.4609 - val_mse: 345.4609\n",
      "Epoch 117/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 59.6830 - mse: 59.6830 - val_loss: 366.6902 - val_mse: 366.6902\n",
      "Epoch 118/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 53.8093 - mse: 53.8093 - val_loss: 343.7292 - val_mse: 343.7292\n",
      "Epoch 119/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 63.9171 - mse: 63.9171 - val_loss: 334.0105 - val_mse: 334.0105\n",
      "Epoch 120/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 55.7845 - mse: 55.7845 - val_loss: 347.6789 - val_mse: 347.6789\n",
      "Epoch 121/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 55.2006 - mse: 55.2006 - val_loss: 374.8432 - val_mse: 374.8432\n",
      "Epoch 122/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 75.3749 - mse: 75.3749 - val_loss: 372.7094 - val_mse: 372.7094\n",
      "Epoch 123/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 71.4870 - mse: 71.4870 - val_loss: 315.6805 - val_mse: 315.6805\n",
      "Epoch 124/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 78.0180 - mse: 78.0180 - val_loss: 369.2758 - val_mse: 369.2758\n",
      "Epoch 125/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 112.5236 - mse: 112.5236 - val_loss: 393.0098 - val_mse: 393.0098\n",
      "Epoch 126/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 120.5994 - mse: 120.5994 - val_loss: 373.0276 - val_mse: 373.0276\n",
      "Epoch 127/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 86.5980 - mse: 86.5980 - val_loss: 361.1253 - val_mse: 361.1253\n",
      "Epoch 128/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 82.8346 - mse: 82.8346 - val_loss: 375.7046 - val_mse: 375.7046\n",
      "Epoch 129/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 105.0417 - mse: 105.0417 - val_loss: 344.0924 - val_mse: 344.0924\n",
      "Epoch 130/300\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 78.6521 - mse: 78.6521 - val_loss: 329.2545 - val_mse: 329.2545\n",
      "Epoch 131/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 75.9215 - mse: 75.9215 - val_loss: 361.5156 - val_mse: 361.5156\n",
      "Epoch 132/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 84.7375 - mse: 84.7375 - val_loss: 323.9751 - val_mse: 323.9751\n",
      "Epoch 133/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 58.2731 - mse: 58.2731 - val_loss: 339.7404 - val_mse: 339.7404\n",
      "Epoch 134/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 55.3781 - mse: 55.3781 - val_loss: 317.6003 - val_mse: 317.6003\n",
      "Epoch 135/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 65.8275 - mse: 65.8275 - val_loss: 340.6165 - val_mse: 340.6165\n",
      "Epoch 136/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 66.6628 - mse: 66.6628 - val_loss: 376.8089 - val_mse: 376.8089\n",
      "Epoch 137/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 77.9376 - mse: 77.9376 - val_loss: 340.5598 - val_mse: 340.5598\n",
      "Epoch 138/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 64.6234 - mse: 64.6234 - val_loss: 330.3750 - val_mse: 330.3750\n",
      "Epoch 139/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 71.1062 - mse: 71.1062 - val_loss: 378.9945 - val_mse: 378.9945\n",
      "Epoch 140/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 71.8787 - mse: 71.8787 - val_loss: 337.4529 - val_mse: 337.4529\n",
      "Epoch 141/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 62.4045 - mse: 62.4045 - val_loss: 344.5298 - val_mse: 344.5298\n",
      "Epoch 142/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 72.3780 - mse: 72.3780 - val_loss: 342.6302 - val_mse: 342.6302\n",
      "Epoch 143/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 66.8290 - mse: 66.8290 - val_loss: 282.9815 - val_mse: 282.9815\n",
      "Epoch 144/300\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 72.9998 - mse: 72.9998 - val_loss: 360.8051 - val_mse: 360.8051\n",
      "Epoch 145/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 57.6309 - mse: 57.6309 - val_loss: 305.3155 - val_mse: 305.3155\n",
      "Epoch 146/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 58.3982 - mse: 58.3982 - val_loss: 326.5822 - val_mse: 326.5822\n",
      "Epoch 147/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 55.1394 - mse: 55.1394 - val_loss: 326.5792 - val_mse: 326.5792\n",
      "Epoch 148/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 57.9978 - mse: 57.9978 - val_loss: 354.7896 - val_mse: 354.7896\n",
      "Epoch 149/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 65.0621 - mse: 65.0621 - val_loss: 366.8974 - val_mse: 366.8974\n",
      "Epoch 150/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 87.3725 - mse: 87.3725 - val_loss: 374.7800 - val_mse: 374.7800\n",
      "Epoch 151/300\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 103.8736 - mse: 103.8736 - val_loss: 346.0810 - val_mse: 346.0810\n",
      "Epoch 152/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 102.2711 - mse: 102.2711 - val_loss: 369.9284 - val_mse: 369.9284\n",
      "Epoch 153/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 129.7121 - mse: 129.7121 - val_loss: 356.5148 - val_mse: 356.5148\n",
      "Epoch 154/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 76.0749 - mse: 76.0749 - val_loss: 310.5614 - val_mse: 310.5614\n",
      "Epoch 155/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 54.4087 - mse: 54.4087 - val_loss: 341.4894 - val_mse: 341.4894\n",
      "Epoch 156/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 50.8842 - mse: 50.8842 - val_loss: 320.2562 - val_mse: 320.2562\n",
      "Epoch 157/300\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 62.0172 - mse: 62.0172 - val_loss: 335.9678 - val_mse: 335.9678\n",
      "Epoch 158/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 62.2527 - mse: 62.2527 - val_loss: 348.6803 - val_mse: 348.6803\n",
      "Epoch 159/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 69.0514 - mse: 69.0514 - val_loss: 405.0010 - val_mse: 405.0010\n",
      "Epoch 160/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 78.8637 - mse: 78.8637 - val_loss: 317.8100 - val_mse: 317.8100\n",
      "Epoch 161/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 78.8197 - mse: 78.8197 - val_loss: 344.0820 - val_mse: 344.0820\n",
      "Epoch 162/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 68.5586 - mse: 68.5586 - val_loss: 349.4805 - val_mse: 349.4805\n",
      "Epoch 163/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 56.3069 - mse: 56.3069 - val_loss: 342.0968 - val_mse: 342.0968\n",
      "Epoch 164/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 70.6126 - mse: 70.6126 - val_loss: 324.7632 - val_mse: 324.7632\n",
      "Epoch 165/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 58.0354 - mse: 58.0354 - val_loss: 333.2947 - val_mse: 333.2947\n",
      "Epoch 166/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 97.2451 - mse: 97.2451 - val_loss: 474.3708 - val_mse: 474.3708\n",
      "Epoch 167/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 113.6929 - mse: 113.6929 - val_loss: 374.5067 - val_mse: 374.5067\n",
      "Epoch 168/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 88.0745 - mse: 88.0745 - val_loss: 356.7961 - val_mse: 356.7961\n",
      "Epoch 169/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 89.7579 - mse: 89.7579 - val_loss: 348.7084 - val_mse: 348.7084\n",
      "Epoch 170/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 66.9790 - mse: 66.9790 - val_loss: 365.7951 - val_mse: 365.7951\n",
      "Epoch 171/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 71.9690 - mse: 71.9690 - val_loss: 340.6905 - val_mse: 340.6905\n",
      "Epoch 172/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 79.3566 - mse: 79.3566 - val_loss: 373.4188 - val_mse: 373.4188\n",
      "Epoch 173/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 59.9137 - mse: 59.9137 - val_loss: 332.9783 - val_mse: 332.9783\n",
      "Epoch 174/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 63.8368 - mse: 63.8368 - val_loss: 346.7797 - val_mse: 346.7797\n",
      "Epoch 175/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 78.9065 - mse: 78.9065 - val_loss: 344.6862 - val_mse: 344.6862\n",
      "Epoch 176/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 113.8876 - mse: 113.8876 - val_loss: 336.5294 - val_mse: 336.5294\n",
      "Epoch 177/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 73.4990 - mse: 73.4990 - val_loss: 341.5406 - val_mse: 341.5406\n",
      "Epoch 178/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 65.0402 - mse: 65.0402 - val_loss: 354.1434 - val_mse: 354.1434\n",
      "Epoch 179/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 86.0277 - mse: 86.0277 - val_loss: 348.8965 - val_mse: 348.8965\n",
      "Epoch 180/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 95.2674 - mse: 95.2674 - val_loss: 411.6589 - val_mse: 411.6589\n",
      "Epoch 181/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 164.2307 - mse: 164.2307 - val_loss: 382.0710 - val_mse: 382.0710\n",
      "Epoch 182/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 74.2082 - mse: 74.2082 - val_loss: 374.7491 - val_mse: 374.7491\n",
      "Epoch 183/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 58.7736 - mse: 58.7736 - val_loss: 357.8356 - val_mse: 357.8356\n",
      "Epoch 184/300\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 60.2680 - mse: 60.2680 - val_loss: 336.1508 - val_mse: 336.1508\n",
      "Epoch 185/300\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 61.7560 - mse: 61.7560 - val_loss: 336.7566 - val_mse: 336.7566\n",
      "Epoch 186/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 74.8416 - mse: 74.8416 - val_loss: 351.7983 - val_mse: 351.7983\n",
      "Epoch 187/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 54.8798 - mse: 54.8798 - val_loss: 352.4295 - val_mse: 352.4295\n",
      "Epoch 188/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 47.7649 - mse: 47.7649 - val_loss: 321.0225 - val_mse: 321.0225\n",
      "Epoch 189/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 66.8341 - mse: 66.8341 - val_loss: 407.5293 - val_mse: 407.5293\n",
      "Epoch 190/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 57.0119 - mse: 57.0119 - val_loss: 371.7032 - val_mse: 371.7032\n",
      "Epoch 191/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 69.7153 - mse: 69.7153 - val_loss: 365.8347 - val_mse: 365.8347\n",
      "Epoch 192/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 75.7757 - mse: 75.7757 - val_loss: 360.4610 - val_mse: 360.4610\n",
      "Epoch 193/300\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 89.9930 - mse: 89.9930 - val_loss: 388.1352 - val_mse: 388.1352\n",
      "Epoch 194/300\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 85.5357 - mse: 85.5357 - val_loss: 393.5354 - val_mse: 393.5354\n",
      "Epoch 195/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 88.4175 - mse: 88.4175 - val_loss: 342.3450 - val_mse: 342.3450\n",
      "Epoch 196/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 99.9902 - mse: 99.9902 - val_loss: 372.4881 - val_mse: 372.4881\n",
      "Epoch 197/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 78.4556 - mse: 78.4556 - val_loss: 370.7667 - val_mse: 370.7667\n",
      "Epoch 198/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 83.2154 - mse: 83.2154 - val_loss: 351.1876 - val_mse: 351.1876\n",
      "Epoch 199/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 93.1949 - mse: 93.1949 - val_loss: 445.5952 - val_mse: 445.5952\n",
      "Epoch 200/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 107.9377 - mse: 107.9377 - val_loss: 408.0068 - val_mse: 408.0068\n",
      "Epoch 201/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 81.2107 - mse: 81.2107 - val_loss: 350.2892 - val_mse: 350.2892\n",
      "Epoch 202/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 56.6074 - mse: 56.6074 - val_loss: 339.8610 - val_mse: 339.8610\n",
      "Epoch 203/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 61.1232 - mse: 61.1232 - val_loss: 518.8818 - val_mse: 518.8818\n",
      "Epoch 204/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 66.0852 - mse: 66.0852 - val_loss: 340.3709 - val_mse: 340.3709\n",
      "Epoch 205/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 58.8249 - mse: 58.8249 - val_loss: 383.1763 - val_mse: 383.1763\n",
      "Epoch 206/300\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 72.7973 - mse: 72.7973 - val_loss: 381.7021 - val_mse: 381.7021\n",
      "Epoch 207/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 62.4473 - mse: 62.4473 - val_loss: 368.5558 - val_mse: 368.5558\n",
      "Epoch 208/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 52.3151 - mse: 52.3151 - val_loss: 353.2571 - val_mse: 353.2571\n",
      "Epoch 209/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 56.4277 - mse: 56.4277 - val_loss: 348.3264 - val_mse: 348.3264\n",
      "Epoch 210/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 52.7852 - mse: 52.7852 - val_loss: 330.9377 - val_mse: 330.9377\n",
      "Epoch 211/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 56.8828 - mse: 56.8828 - val_loss: 363.0123 - val_mse: 363.0123\n",
      "Epoch 212/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 42.8447 - mse: 42.8447 - val_loss: 347.8748 - val_mse: 347.8748\n",
      "Epoch 213/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 74.1159 - mse: 74.1159 - val_loss: 425.8582 - val_mse: 425.8582\n",
      "Epoch 214/300\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 101.2476 - mse: 101.2476 - val_loss: 408.2141 - val_mse: 408.2141\n",
      "Epoch 215/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 91.4945 - mse: 91.4945 - val_loss: 341.6509 - val_mse: 341.6509\n",
      "Epoch 216/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 62.8012 - mse: 62.8012 - val_loss: 359.4639 - val_mse: 359.4639\n",
      "Epoch 217/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 67.0595 - mse: 67.0595 - val_loss: 351.4224 - val_mse: 351.4224\n",
      "Epoch 218/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 73.5634 - mse: 73.5634 - val_loss: 412.0433 - val_mse: 412.0433\n",
      "Epoch 219/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 77.1997 - mse: 77.1997 - val_loss: 375.1423 - val_mse: 375.1423\n",
      "Epoch 220/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 72.4674 - mse: 72.4674 - val_loss: 366.2942 - val_mse: 366.2942\n",
      "Epoch 221/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 50.8748 - mse: 50.8748 - val_loss: 345.4112 - val_mse: 345.4112\n",
      "Epoch 222/300\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 48.6050 - mse: 48.6050 - val_loss: 357.1742 - val_mse: 357.1742\n",
      "Epoch 223/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 57.5067 - mse: 57.5067 - val_loss: 356.3156 - val_mse: 356.3156\n",
      "Epoch 224/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 59.4440 - mse: 59.4440 - val_loss: 347.3015 - val_mse: 347.3015\n",
      "Epoch 225/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 123.4515 - mse: 123.4515 - val_loss: 403.8889 - val_mse: 403.8889\n",
      "Epoch 226/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 98.6313 - mse: 98.6313 - val_loss: 375.9896 - val_mse: 375.9896\n",
      "Epoch 227/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 63.0125 - mse: 63.0125 - val_loss: 313.3439 - val_mse: 313.3439\n",
      "Epoch 228/300\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 68.8396 - mse: 68.8396 - val_loss: 379.9622 - val_mse: 379.9622\n",
      "Epoch 229/300\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 59.8903 - mse: 59.8903 - val_loss: 342.4577 - val_mse: 342.4577\n",
      "Epoch 230/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 73.2183 - mse: 73.2183 - val_loss: 363.1849 - val_mse: 363.1849\n",
      "Epoch 231/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 54.2748 - mse: 54.2748 - val_loss: 330.1553 - val_mse: 330.1553\n",
      "Epoch 232/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 34.4091 - mse: 34.4091 - val_loss: 323.0304 - val_mse: 323.0304\n",
      "Epoch 233/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 47.5402 - mse: 47.5402 - val_loss: 342.9707 - val_mse: 342.9707\n",
      "Epoch 234/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 49.0941 - mse: 49.0941 - val_loss: 359.4788 - val_mse: 359.4788\n",
      "Epoch 235/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 58.0834 - mse: 58.0834 - val_loss: 342.7212 - val_mse: 342.7212\n",
      "Epoch 236/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 41.5847 - mse: 41.5847 - val_loss: 360.3874 - val_mse: 360.3874\n",
      "Epoch 237/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 57.4995 - mse: 57.4995 - val_loss: 360.0665 - val_mse: 360.0665\n",
      "Epoch 238/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 62.2815 - mse: 62.2815 - val_loss: 366.0194 - val_mse: 366.0194\n",
      "Epoch 239/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 77.3236 - mse: 77.3236 - val_loss: 366.9093 - val_mse: 366.9093\n",
      "Epoch 240/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 82.6239 - mse: 82.6239 - val_loss: 381.9576 - val_mse: 381.9576\n",
      "Epoch 241/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 84.1909 - mse: 84.1909 - val_loss: 360.5313 - val_mse: 360.5313\n",
      "Epoch 242/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 71.9315 - mse: 71.9315 - val_loss: 402.4362 - val_mse: 402.4362\n",
      "Epoch 243/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 72.7620 - mse: 72.7620 - val_loss: 332.4890 - val_mse: 332.4890\n",
      "Epoch 244/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 53.3095 - mse: 53.3095 - val_loss: 350.9034 - val_mse: 350.9034\n",
      "Epoch 245/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 60.8123 - mse: 60.8123 - val_loss: 367.8414 - val_mse: 367.8414\n",
      "Epoch 246/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 64.5566 - mse: 64.5566 - val_loss: 358.5637 - val_mse: 358.5637\n",
      "Epoch 247/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 63.2374 - mse: 63.2374 - val_loss: 383.1973 - val_mse: 383.1973\n",
      "Epoch 248/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 60.7762 - mse: 60.7762 - val_loss: 352.2926 - val_mse: 352.2926\n",
      "Epoch 249/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 60.2392 - mse: 60.2392 - val_loss: 340.9552 - val_mse: 340.9552\n",
      "Epoch 250/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 59.8080 - mse: 59.8080 - val_loss: 406.5310 - val_mse: 406.5310\n",
      "Epoch 251/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 64.7241 - mse: 64.7241 - val_loss: 378.7215 - val_mse: 378.7215\n",
      "Epoch 252/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 66.2630 - mse: 66.2630 - val_loss: 391.8283 - val_mse: 391.8283\n",
      "Epoch 253/300\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 51.4441 - mse: 51.4441 - val_loss: 341.6794 - val_mse: 341.6794\n",
      "Epoch 254/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 68.3688 - mse: 68.3688 - val_loss: 350.5265 - val_mse: 350.5265\n",
      "Epoch 255/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 60.8438 - mse: 60.8438 - val_loss: 446.5886 - val_mse: 446.5886\n",
      "Epoch 256/300\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 59.3173 - mse: 59.3173 - val_loss: 333.5141 - val_mse: 333.5141\n",
      "Epoch 257/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 46.2541 - mse: 46.2541 - val_loss: 352.4209 - val_mse: 352.4209\n",
      "Epoch 258/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 49.6092 - mse: 49.6092 - val_loss: 363.0305 - val_mse: 363.0305\n",
      "Epoch 259/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 59.6674 - mse: 59.6674 - val_loss: 324.5706 - val_mse: 324.5706\n",
      "Epoch 260/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 37.2844 - mse: 37.2844 - val_loss: 326.8845 - val_mse: 326.8845\n",
      "Epoch 261/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 43.7312 - mse: 43.7312 - val_loss: 337.1552 - val_mse: 337.1552\n",
      "Epoch 262/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 60.3768 - mse: 60.3768 - val_loss: 380.6443 - val_mse: 380.6443\n",
      "Epoch 263/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 76.8953 - mse: 76.8953 - val_loss: 314.1005 - val_mse: 314.1005\n",
      "Epoch 264/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 60.8468 - mse: 60.8468 - val_loss: 371.9133 - val_mse: 371.9133\n",
      "Epoch 265/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 55.6563 - mse: 55.6563 - val_loss: 339.3651 - val_mse: 339.3651\n",
      "Epoch 266/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 50.2671 - mse: 50.2671 - val_loss: 399.8217 - val_mse: 399.8217\n",
      "Epoch 267/300\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 50.4168 - mse: 50.4168 - val_loss: 362.3833 - val_mse: 362.3833\n",
      "Epoch 268/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 46.3131 - mse: 46.3131 - val_loss: 377.3298 - val_mse: 377.3298\n",
      "Epoch 269/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 61.0012 - mse: 61.0012 - val_loss: 383.3378 - val_mse: 383.3378\n",
      "Epoch 270/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 55.8728 - mse: 55.8728 - val_loss: 417.8924 - val_mse: 417.8924\n",
      "Epoch 271/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 61.0636 - mse: 61.0636 - val_loss: 350.7994 - val_mse: 350.7994\n",
      "Epoch 272/300\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 70.8281 - mse: 70.8281 - val_loss: 402.7641 - val_mse: 402.7641\n",
      "Epoch 273/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 115.6535 - mse: 115.6535 - val_loss: 728.8512 - val_mse: 728.8512\n",
      "Epoch 274/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 117.0170 - mse: 117.0170 - val_loss: 378.4956 - val_mse: 378.4956\n",
      "Epoch 275/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 70.8489 - mse: 70.8489 - val_loss: 328.7990 - val_mse: 328.7990\n",
      "Epoch 276/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 57.5298 - mse: 57.5298 - val_loss: 367.3870 - val_mse: 367.3870\n",
      "Epoch 277/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 54.4855 - mse: 54.4855 - val_loss: 357.5672 - val_mse: 357.5672\n",
      "Epoch 278/300\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 56.8103 - mse: 56.8103 - val_loss: 309.6360 - val_mse: 309.6360\n",
      "Epoch 279/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 93.0730 - mse: 93.0730 - val_loss: 547.1182 - val_mse: 547.1182\n",
      "Epoch 280/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 93.2007 - mse: 93.2007 - val_loss: 439.0385 - val_mse: 439.0385\n",
      "Epoch 281/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 77.8436 - mse: 77.8436 - val_loss: 431.6464 - val_mse: 431.6464\n",
      "Epoch 282/300\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 89.7084 - mse: 89.7084 - val_loss: 459.4754 - val_mse: 459.4754\n",
      "Epoch 283/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 69.5518 - mse: 69.5518 - val_loss: 395.1088 - val_mse: 395.1088\n",
      "Epoch 284/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 53.7519 - mse: 53.7519 - val_loss: 491.5959 - val_mse: 491.5959\n",
      "Epoch 285/300\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 52.8976 - mse: 52.8976 - val_loss: 395.8633 - val_mse: 395.8633\n",
      "Epoch 286/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 60.6900 - mse: 60.6900 - val_loss: 445.8390 - val_mse: 445.8390\n",
      "Epoch 287/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 80.3830 - mse: 80.3830 - val_loss: 438.1570 - val_mse: 438.1570\n",
      "Epoch 288/300\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 60.9067 - mse: 60.9067 - val_loss: 400.5019 - val_mse: 400.5019\n",
      "Epoch 289/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 51.8371 - mse: 51.8371 - val_loss: 381.3124 - val_mse: 381.3124\n",
      "Epoch 290/300\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 47.4071 - mse: 47.4071 - val_loss: 443.7535 - val_mse: 443.7535\n",
      "Epoch 291/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 57.3719 - mse: 57.3719 - val_loss: 385.3374 - val_mse: 385.3374\n",
      "Epoch 292/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 67.7025 - mse: 67.7025 - val_loss: 402.6742 - val_mse: 402.6742\n",
      "Epoch 293/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 40.6610 - mse: 40.6610 - val_loss: 383.4905 - val_mse: 383.4905\n",
      "Epoch 294/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 40.3244 - mse: 40.3244 - val_loss: 385.0476 - val_mse: 385.0476\n",
      "Epoch 295/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 43.4142 - mse: 43.4142 - val_loss: 387.7203 - val_mse: 387.7203\n",
      "Epoch 296/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 54.7498 - mse: 54.7498 - val_loss: 407.8398 - val_mse: 407.8398\n",
      "Epoch 297/300\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 43.8744 - mse: 43.8744 - val_loss: 389.9012 - val_mse: 389.9012\n",
      "Epoch 298/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 45.1263 - mse: 45.1263 - val_loss: 443.5232 - val_mse: 443.5232\n",
      "Epoch 299/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 38.9544 - mse: 38.9544 - val_loss: 391.9851 - val_mse: 391.9851\n",
      "Epoch 300/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 46.8781 - mse: 46.8781 - val_loss: 412.9582 - val_mse: 412.9582\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x191bbc1a730>"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.fit(x_train3, y_train3, batch_size=16, epochs=300, validation_data=(x_test3,y_test3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions3 = model_3.predict(x_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rezultati2 = pd.DataFrame({'pred':predictions3.reshape(-1,), 'test':y_test3})\n",
    "df_rezultati2['diff'] = df_rezultati2['test'] - df_rezultati2['pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  6., 48., 66., 11.,\n",
       "         3.,  3.]),\n",
       " array([-219.67895508, -199.85128733, -180.02361959, -160.19595184,\n",
       "        -140.3682841 , -120.54061635, -100.71294861,  -80.88528086,\n",
       "         -61.05761312,  -41.22994537,  -21.40227763,   -1.57460988,\n",
       "          18.25305786,   38.08072561,   57.90839335,   77.7360611 ]),\n",
       " <BarContainer object of 15 artists>)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df_rezultati2[\"diff\"], bins=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.82970355626156\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rmse = mean_squared_error(predictions3,y_test3,squared=False)\n",
    "print(rmse/y_test3.mean()*100)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "50c5e99bf4ebd5b12b172150eb5a5c1f0c5d53cea0aeb0ef1e5deb10d0bca0e6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('AGprojekt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
